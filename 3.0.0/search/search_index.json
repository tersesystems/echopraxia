{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Echopraxia \u00b6 Echopraxia is a Java logging API designed around structured logging, rich context, and conditional logging. There are Logback and Log4J2 implementations, but Echopraxia's API is completely dependency-free, meaning it can be implemented with any logging API, i.e. jboss-logging, JUL, JEP 264, or even directly. What this means is that all arguments in a logging statement have a name and a value, for example: logger . info ( \"arg1 is {} and arg2 is {}\" , fb -> fb . list ( fb . string ( \"name\" , \"value\" ), fb . number ( \"age\" , 13 ) )); writes out in logfmt as: INFO 13.232 arg1 is name=value and arg2 is age=13 and in a JSON format as: { \"message\" : \"arg1 is name=value and arg2 is age=13\" , \"name\" : \"value\" , \"age\" : 13 } What makes Echopraxia effective -- especially for debugging -- is that you can define your own field builders to map between objects and fields, and then pass in your own objects and render complex objects. For example, we can render a Person object: Logger < PersonFieldBuilder > logger = LoggerFactory . getLogger ( getClass ()) . withFieldBuilder ( PersonFieldBuilder . instance ()); Person abe = new Person ( \"Abe\" , 1 , \"yodelling\" ); abe . setFather ( new Person ( \"Bert\" , 35 , \"keyboards\" )); abe . setMother ( new Person ( \"Candace\" , 30 , \"iceskating\" )); logger . info ( \"{}\" , fb -> fb . person ( \"abe\" , abe )); And print out the internal state of the Person in both logfmt and JSON. INFO 13.223 abe={Abe, 1, father={Bert, 35, father=null, mother=null, interests=[keyboards]}, mother={Candace, 30, father=null, mother=null, interests=[iceskating]}, interests=[yodelling]} Echopraxia also has a \"contextual\" logging feature that renders fields in JSON: var fooLogger = logger . withFields ( fb -> fb . string ( \"foo\" , \"bar\" )); fooLogger . info ( \"This logs the 'foo' field automatically in JSON\" ); And has conditional logging based on fields and exceptions using JSONPath: Condition c = ( level , ctx ) -> ctx . findString ( \"$.exception.stackTrace[0].methodName\" ) . filter ( s -> s . endsWith ( \"Foo\" )) . isPresent (); logger . error ( c , \"Only render this error if method name ends in Foo\" , e ); And there is also a feature to change logging conditions dynamically using scripts . Examples \u00b6 For the fastest possible way to try out Echopraxia, download and run the JBang script . Simple examples and integrations with dropwizard metrics and OSHI are available at echopraxia-examples . For a web application example, see this Spring Boot Project . Scala API \u00b6 There is a Scala API available at https://github.com/tersesystems/echopraxia-plusscala .","title":"Home"},{"location":"#echopraxia","text":"Echopraxia is a Java logging API designed around structured logging, rich context, and conditional logging. There are Logback and Log4J2 implementations, but Echopraxia's API is completely dependency-free, meaning it can be implemented with any logging API, i.e. jboss-logging, JUL, JEP 264, or even directly. What this means is that all arguments in a logging statement have a name and a value, for example: logger . info ( \"arg1 is {} and arg2 is {}\" , fb -> fb . list ( fb . string ( \"name\" , \"value\" ), fb . number ( \"age\" , 13 ) )); writes out in logfmt as: INFO 13.232 arg1 is name=value and arg2 is age=13 and in a JSON format as: { \"message\" : \"arg1 is name=value and arg2 is age=13\" , \"name\" : \"value\" , \"age\" : 13 } What makes Echopraxia effective -- especially for debugging -- is that you can define your own field builders to map between objects and fields, and then pass in your own objects and render complex objects. For example, we can render a Person object: Logger < PersonFieldBuilder > logger = LoggerFactory . getLogger ( getClass ()) . withFieldBuilder ( PersonFieldBuilder . instance ()); Person abe = new Person ( \"Abe\" , 1 , \"yodelling\" ); abe . setFather ( new Person ( \"Bert\" , 35 , \"keyboards\" )); abe . setMother ( new Person ( \"Candace\" , 30 , \"iceskating\" )); logger . info ( \"{}\" , fb -> fb . person ( \"abe\" , abe )); And print out the internal state of the Person in both logfmt and JSON. INFO 13.223 abe={Abe, 1, father={Bert, 35, father=null, mother=null, interests=[keyboards]}, mother={Candace, 30, father=null, mother=null, interests=[iceskating]}, interests=[yodelling]} Echopraxia also has a \"contextual\" logging feature that renders fields in JSON: var fooLogger = logger . withFields ( fb -> fb . string ( \"foo\" , \"bar\" )); fooLogger . info ( \"This logs the 'foo' field automatically in JSON\" ); And has conditional logging based on fields and exceptions using JSONPath: Condition c = ( level , ctx ) -> ctx . findString ( \"$.exception.stackTrace[0].methodName\" ) . filter ( s -> s . endsWith ( \"Foo\" )) . isPresent (); logger . error ( c , \"Only render this error if method name ends in Foo\" , e ); And there is also a feature to change logging conditions dynamically using scripts .","title":"Echopraxia"},{"location":"#examples","text":"For the fastest possible way to try out Echopraxia, download and run the JBang script . Simple examples and integrations with dropwizard metrics and OSHI are available at echopraxia-examples . For a web application example, see this Spring Boot Project .","title":"Examples"},{"location":"#scala-api","text":"There is a Scala API available at https://github.com/tersesystems/echopraxia-plusscala .","title":"Scala API"},{"location":"faq/","text":"Freqently Asked Questions \u00b6 Is this a replacement for SLF4J and/or Log4J? \u00b6 Echopraxia is not a replacement for SLF4J . It is not an attempt to compete with Log4J2 API, JUL, commons-logging for the title of \"one true logging API\" and restart the logging mess . SLF4J won that fight a long time ago . Echopraxia is a structured logging API -- it gives the user the ability to provide structured input directly from the application. It is an appropriate solution when you control the logging implementation and have decided you're going to do structured logging output, e.g. a web application where you've decided to use logstash-logback-encoder . SLF4J is an appropriate solution when you do not control the logging output , e.g. in an open-source library that could be used in arbitrary situations by anybody. Echopraxia is best described as a specialization or augmentation for application code -- as you're building framework support code for your application and build up your domain objects, you can write custom field builders, then log everywhere in your application with a consistent schema. Why Structured Logging? \u00b6 Structured logging enables logs to be queried as semi-structured data . There are other structured logging frameworks, like Structlog (Python), Ruby-Cabin (Ruby), Logrus (Go), and Serilog (C#). Ruby-Cabin has the best take on this: Structured data means you don't need crazy regular expression skills to make sense of logs. From a logging API perspective, structured logging is interesting because it is composable -- structured data can be added to a logger and build up context. You can read more about structured logging here . Why Conditions? \u00b6 Conditions address the challenge of \"whether-to-log\", which concerns with dynamically adjusting the degree of logging in response to the runtime requirements. A statement is only logged if it passes the condition associated with it. Conditions can leverage the data exposed by structured logging. For example, here's a debug statement that only logs if the remote address is localhost: Condition isLocalhost = ( level , ctx ) -> ctx . findString ( \"$.request_remote_addr\" ) . map ( s -> Objects . equals ( s , \"127.0.0.1\" )) . orElse ( false ); logger . debug ( isLocalhost , \"address is {}\" , fb -> fb . string ( \"request_remote_addr\" , addr )); This makes targeted logging far more powerful, because diagnostic logging is no longer an \"all or nothing\" proposition -- conditions can dynamically filter what is logged, creating a \"control plane\" for logging. A proof of concept of dynamic debug logging using Echopraxia is here . A Comprehensive Survey of Logging in Software and The Bones of the System: A Study of Logging and Telemetry at Microsoft are great discussions of the implication of being able to adjust logging conditions at runtime.","title":"FAQ"},{"location":"faq/#freqently-asked-questions","text":"","title":"Freqently Asked Questions"},{"location":"faq/#is-this-a-replacement-for-slf4j-andor-log4j","text":"Echopraxia is not a replacement for SLF4J . It is not an attempt to compete with Log4J2 API, JUL, commons-logging for the title of \"one true logging API\" and restart the logging mess . SLF4J won that fight a long time ago . Echopraxia is a structured logging API -- it gives the user the ability to provide structured input directly from the application. It is an appropriate solution when you control the logging implementation and have decided you're going to do structured logging output, e.g. a web application where you've decided to use logstash-logback-encoder . SLF4J is an appropriate solution when you do not control the logging output , e.g. in an open-source library that could be used in arbitrary situations by anybody. Echopraxia is best described as a specialization or augmentation for application code -- as you're building framework support code for your application and build up your domain objects, you can write custom field builders, then log everywhere in your application with a consistent schema.","title":"Is this a replacement for SLF4J and/or Log4J?"},{"location":"faq/#why-structured-logging","text":"Structured logging enables logs to be queried as semi-structured data . There are other structured logging frameworks, like Structlog (Python), Ruby-Cabin (Ruby), Logrus (Go), and Serilog (C#). Ruby-Cabin has the best take on this: Structured data means you don't need crazy regular expression skills to make sense of logs. From a logging API perspective, structured logging is interesting because it is composable -- structured data can be added to a logger and build up context. You can read more about structured logging here .","title":"Why Structured Logging?"},{"location":"faq/#why-conditions","text":"Conditions address the challenge of \"whether-to-log\", which concerns with dynamically adjusting the degree of logging in response to the runtime requirements. A statement is only logged if it passes the condition associated with it. Conditions can leverage the data exposed by structured logging. For example, here's a debug statement that only logs if the remote address is localhost: Condition isLocalhost = ( level , ctx ) -> ctx . findString ( \"$.request_remote_addr\" ) . map ( s -> Objects . equals ( s , \"127.0.0.1\" )) . orElse ( false ); logger . debug ( isLocalhost , \"address is {}\" , fb -> fb . string ( \"request_remote_addr\" , addr )); This makes targeted logging far more powerful, because diagnostic logging is no longer an \"all or nothing\" proposition -- conditions can dynamically filter what is logged, creating a \"control plane\" for logging. A proof of concept of dynamic debug logging using Echopraxia is here . A Comprehensive Survey of Logging in Software and The Bones of the System: A Study of Logging and Telemetry at Microsoft are great discussions of the implication of being able to adjust logging conditions at runtime.","title":"Why Conditions?"},{"location":"installation/","text":"Installation \u00b6 Echopraxia is divided into two sections: the user logger APIs ( logger , fluent , semantic ) and an underlying CoreLogger implementation which is tied to the logging framework. You will need to install both, although in 99% of cases you will want logger : Maven: <dependency> <groupId> com.tersesystems.echopraxia </groupId> <artifactId> logger </artifactId> <version> VERSION </version> </dependency> Gradle: implementation \"com.tersesystems.echopraxia:logger:<VERSION>\" There are core loggers for Logback, Log4J2, and JUL. Logstash Core Logger \u00b6 There is a Logback implementation based around logstash-logback-encoder . This library does not provide a front end logger API, so you must pick (or create) one yourself, i.e. normal, async, fluent, or semantic. Maven: <dependency> <groupId> com.tersesystems.echopraxia </groupId> <artifactId> logstash </artifactId> <version><VERSION></version> </dependency> Gradle: implementation \"com.tersesystems.echopraxia:logstash:<VERSION>\" Because Logback 1.2 is compiled with SLF4J 1.7.x and Logback 1.3 uses SLF4J 2.x, Echopraxia does not include the transitive dependencies. Instead, you will need to select the appropriate Logback implementation: For SLF4J 1.7.x: implementation \"ch.qos.logback:logback-classic:1.2.12\" implementation 'net.logstash.logback:logstash-logback-encoder:7.3' For SLF4J 2.0.x and for logstash-logback-encoder from 7.4: implementation \"ch.qos.logback:logback-classic:1.4.6\" implementation 'net.logstash.logback:logstash-logback-encoder:7.4' Log4J Core Logger \u00b6 There is a Log4J implementation that works with the JSON Template Layout . This provides a core logger implementation but does not provide a user visible logging API. Maven: <dependency> <groupId> com.tersesystems.echopraxia </groupId> <artifactId> log4j </artifactId> <version><VERSION></version> </dependency> Gradle: implementation \"com.tersesystems.echopraxia:log4j:<VERSION>\" You should explicitly define the Log4J dependencies as well: implementation \"org.apache.logging.log4j:log4j-core:$log4j2Version\" implementation \"org.apache.logging.log4j:log4j-api:$log4j2Version\" implementation \"org.apache.logging.log4j:log4j-layout-template-json:$log4j2Version\" You will need to integrate the com.tersesystems.echopraxia.log4j.layout package into your log4j2.xml file, e.g. by using the packages attribute, and add an EventTemplateAdditionalField element: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <Configuration status= \"WARN\" packages= \"com.tersesystems.echopraxia.log4j.layout\" > <Appenders> <Console name= \"Console\" target= \"SYSTEM_OUT\" follow= \"true\" > <JsonTemplateLayout eventTemplateUri= \"classpath:LogstashJsonEventLayoutV1.json\" > <EventTemplateAdditionalField key= \"fields\" format= \"JSON\" value= '{\"$resolver\": \"echopraxiaFields\"}' /> </JsonTemplateLayout> </Console> </Appenders> <Loggers> <Root level= \"info\" > <AppenderRef ref= \"Console\" /> </Root> </Loggers> </Configuration> If you want to separate the context fields from the argument fields, you can define them separately: <JsonTemplateLayout eventTemplateUri= \"classpath:LogstashJsonEventLayoutV1.json\" > <EventTemplateAdditionalField key= \"arguments\" format= \"JSON\" value= '{\"$resolver\": \"echopraxiaArgumentFields\"}' /> <EventTemplateAdditionalField key= \"context\" format= \"JSON\" value= '{\"$resolver\": \"echopraxiaContextFields\"}' /> </JsonTemplateLayout> Unfortunately, I don't know of a way to \"flatten\" fields so that they show up on the root object instead of under an additional field. If you know how to do this, let me know! JUL (java.util.logging) Core Logger \u00b6 There is a JUL implementation. Maven: <dependency> <groupId> com.tersesystems.echopraxia </groupId> <artifactId> jul </artifactId> <version><VERSION></version> </dependency> Gradle: implementation \"com.tersesystems.echopraxia:jul:<VERSION>\" You will probably want to configure JUL by calling logManager.readConfiguration : InputStream is ; try { is = getClass (). getClassLoader (). getResourceAsStream ( \"logging.properties\" ); LogManager manager = LogManager . getLogManager (); manager . reset (); manager . readConfiguration ( is ); } finally { if ( is != null ) is . close (); } JSON output is managed using a custom formatter com.tersesystems.echopraxia.jul.JULJSONFormatter : handlers = java.util.logging.ConsoleHandler,java.util.logging.FileHandler .level = FINEST com.tersesystems.echopraxia.jul.JULJSONFormatter.use_slf4j_level_names = true java.util.logging.FileHandler.formatter = com.tersesystems.echopraxia.jul.JULJSONFormatter java.util.logging.ConsoleHandler.formatter = java.util.logging.SimpleFormatter The use_slf4j_level_names property will map from JUL's levels to SLF4J, mapping FINE and FINER to DEBUG and FINEST to TRACE . JUL's default class/method inference is disabled as it is not useful here and needlessly slows down logging.","title":"Installation"},{"location":"installation/#installation","text":"Echopraxia is divided into two sections: the user logger APIs ( logger , fluent , semantic ) and an underlying CoreLogger implementation which is tied to the logging framework. You will need to install both, although in 99% of cases you will want logger : Maven: <dependency> <groupId> com.tersesystems.echopraxia </groupId> <artifactId> logger </artifactId> <version> VERSION </version> </dependency> Gradle: implementation \"com.tersesystems.echopraxia:logger:<VERSION>\" There are core loggers for Logback, Log4J2, and JUL.","title":"Installation"},{"location":"installation/#logstash-core-logger","text":"There is a Logback implementation based around logstash-logback-encoder . This library does not provide a front end logger API, so you must pick (or create) one yourself, i.e. normal, async, fluent, or semantic. Maven: <dependency> <groupId> com.tersesystems.echopraxia </groupId> <artifactId> logstash </artifactId> <version><VERSION></version> </dependency> Gradle: implementation \"com.tersesystems.echopraxia:logstash:<VERSION>\" Because Logback 1.2 is compiled with SLF4J 1.7.x and Logback 1.3 uses SLF4J 2.x, Echopraxia does not include the transitive dependencies. Instead, you will need to select the appropriate Logback implementation: For SLF4J 1.7.x: implementation \"ch.qos.logback:logback-classic:1.2.12\" implementation 'net.logstash.logback:logstash-logback-encoder:7.3' For SLF4J 2.0.x and for logstash-logback-encoder from 7.4: implementation \"ch.qos.logback:logback-classic:1.4.6\" implementation 'net.logstash.logback:logstash-logback-encoder:7.4'","title":"Logstash Core Logger"},{"location":"installation/#log4j-core-logger","text":"There is a Log4J implementation that works with the JSON Template Layout . This provides a core logger implementation but does not provide a user visible logging API. Maven: <dependency> <groupId> com.tersesystems.echopraxia </groupId> <artifactId> log4j </artifactId> <version><VERSION></version> </dependency> Gradle: implementation \"com.tersesystems.echopraxia:log4j:<VERSION>\" You should explicitly define the Log4J dependencies as well: implementation \"org.apache.logging.log4j:log4j-core:$log4j2Version\" implementation \"org.apache.logging.log4j:log4j-api:$log4j2Version\" implementation \"org.apache.logging.log4j:log4j-layout-template-json:$log4j2Version\" You will need to integrate the com.tersesystems.echopraxia.log4j.layout package into your log4j2.xml file, e.g. by using the packages attribute, and add an EventTemplateAdditionalField element: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <Configuration status= \"WARN\" packages= \"com.tersesystems.echopraxia.log4j.layout\" > <Appenders> <Console name= \"Console\" target= \"SYSTEM_OUT\" follow= \"true\" > <JsonTemplateLayout eventTemplateUri= \"classpath:LogstashJsonEventLayoutV1.json\" > <EventTemplateAdditionalField key= \"fields\" format= \"JSON\" value= '{\"$resolver\": \"echopraxiaFields\"}' /> </JsonTemplateLayout> </Console> </Appenders> <Loggers> <Root level= \"info\" > <AppenderRef ref= \"Console\" /> </Root> </Loggers> </Configuration> If you want to separate the context fields from the argument fields, you can define them separately: <JsonTemplateLayout eventTemplateUri= \"classpath:LogstashJsonEventLayoutV1.json\" > <EventTemplateAdditionalField key= \"arguments\" format= \"JSON\" value= '{\"$resolver\": \"echopraxiaArgumentFields\"}' /> <EventTemplateAdditionalField key= \"context\" format= \"JSON\" value= '{\"$resolver\": \"echopraxiaContextFields\"}' /> </JsonTemplateLayout> Unfortunately, I don't know of a way to \"flatten\" fields so that they show up on the root object instead of under an additional field. If you know how to do this, let me know!","title":"Log4J Core Logger"},{"location":"installation/#jul-javautillogging-core-logger","text":"There is a JUL implementation. Maven: <dependency> <groupId> com.tersesystems.echopraxia </groupId> <artifactId> jul </artifactId> <version><VERSION></version> </dependency> Gradle: implementation \"com.tersesystems.echopraxia:jul:<VERSION>\" You will probably want to configure JUL by calling logManager.readConfiguration : InputStream is ; try { is = getClass (). getClassLoader (). getResourceAsStream ( \"logging.properties\" ); LogManager manager = LogManager . getLogManager (); manager . reset (); manager . readConfiguration ( is ); } finally { if ( is != null ) is . close (); } JSON output is managed using a custom formatter com.tersesystems.echopraxia.jul.JULJSONFormatter : handlers = java.util.logging.ConsoleHandler,java.util.logging.FileHandler .level = FINEST com.tersesystems.echopraxia.jul.JULJSONFormatter.use_slf4j_level_names = true java.util.logging.FileHandler.formatter = com.tersesystems.echopraxia.jul.JULJSONFormatter java.util.logging.ConsoleHandler.formatter = java.util.logging.SimpleFormatter The use_slf4j_level_names property will map from JUL's levels to SLF4J, mapping FINE and FINER to DEBUG and FINEST to TRACE . JUL's default class/method inference is disabled as it is not useful here and needlessly slows down logging.","title":"JUL (java.util.logging) Core Logger"},{"location":"additional/diff/","text":"Diff Field Builder \u00b6 The \"diff\" field builder is useful for debugging a change in state in complex objects because it can compare \"before\" and \"after\" objects and only render the changes between the two values, using RFC 6902 format with zjsonpatch . To add the diff field builder, add the diff module: implementation \"com.tersesystems.echopraxia:diff:<VERSION>\" And implement DiffFieldBuilder : import com.tersesystems.echopraxia.diff.DiffFieldBuilder ; class PersonFieldBuilder implements DiffFieldBuilder { // ... public FieldBuilderResult diff ( String name , Person before , Person after ) { return diff ( name , personValue ( before ), personValue ( after ), Field . class ); } } You can then compare a change in an object by rendering the diff: Logger < PersonFieldBuilder > logger = LoggerFactory . getLogger (). withFieldBuilder ( PersonFieldBuilder . instance ); Person before = new Person ( \"Jim\" , 1 ); Person after = before . withName ( \"Will\" ); logger . info ( \"{}\" , fb -> fb . diff ( \"personDiff\" , before , after )); The diff field builder depends on Jackson 2.13, and will use a static object mapper by default, which you can override using the _objectMapper method.","title":"Diff Field Builder"},{"location":"additional/diff/#diff-field-builder","text":"The \"diff\" field builder is useful for debugging a change in state in complex objects because it can compare \"before\" and \"after\" objects and only render the changes between the two values, using RFC 6902 format with zjsonpatch . To add the diff field builder, add the diff module: implementation \"com.tersesystems.echopraxia:diff:<VERSION>\" And implement DiffFieldBuilder : import com.tersesystems.echopraxia.diff.DiffFieldBuilder ; class PersonFieldBuilder implements DiffFieldBuilder { // ... public FieldBuilderResult diff ( String name , Person before , Person after ) { return diff ( name , personValue ( before ), personValue ( after ), Field . class ); } } You can then compare a change in an object by rendering the diff: Logger < PersonFieldBuilder > logger = LoggerFactory . getLogger (). withFieldBuilder ( PersonFieldBuilder . instance ); Person before = new Person ( \"Jim\" , 1 ); Person after = before . withName ( \"Will\" ); logger . info ( \"{}\" , fb -> fb . diff ( \"personDiff\" , before , after )); The diff field builder depends on Jackson 2.13, and will use a static object mapper by default, which you can override using the _objectMapper method.","title":"Diff Field Builder"},{"location":"additional/fluent/","text":"Fluent Logger \u00b6 Fluent logging is done using a FluentLoggerFactory . Maven: <dependency> <groupId>com.tersesystems.echopraxia</groupId> <artifactId>fluent</artifactId> <version><VERSION></version> </dependency> Gradle: implementation \"com.tersesystems.echopraxia:fluent:<VERSION>\" It is useful in situations where arguments may need to be built up over time. import com.tersesystems.echopraxia.fluent.* ; FluentLogger < PresentationFieldBuilder > logger = FluentLoggerFactory . getLogger ( getClass ()); Person person = new Person ( \"Eloise\" , 1 ); logger . atInfo () . message ( \"name = {}, age = {}\" ) . argument ( fb -> fb . string ( \"name\" , person . name )) . argument ( fb -> fb . number ( \"age\" , person . age )) . log ();","title":"Fluent Logger"},{"location":"additional/fluent/#fluent-logger","text":"Fluent logging is done using a FluentLoggerFactory . Maven: <dependency> <groupId>com.tersesystems.echopraxia</groupId> <artifactId>fluent</artifactId> <version><VERSION></version> </dependency> Gradle: implementation \"com.tersesystems.echopraxia:fluent:<VERSION>\" It is useful in situations where arguments may need to be built up over time. import com.tersesystems.echopraxia.fluent.* ; FluentLogger < PresentationFieldBuilder > logger = FluentLoggerFactory . getLogger ( getClass ()); Person person = new Person ( \"Eloise\" , 1 ); logger . atInfo () . message ( \"name = {}, age = {}\" ) . argument ( fb -> fb . string ( \"name\" , person . name )) . argument ( fb -> fb . number ( \"age\" , person . age )) . log ();","title":"Fluent Logger"},{"location":"additional/semantic/","text":"Semantic Logger \u00b6 Semantic Loggers are strongly typed, and will only log a particular kind of argument. All the work of field building and setting up a message is done from setup. Installation \u00b6 Semantic Loggers have a dependency on the api module, but do not have any implementation dependencies. Maven: <dependency> <groupId>com.tersesystems.echopraxia</groupId> <artifactId>semantic</artifactId> <version><VERSION></version> </dependency> Gradle: implementation \"com.tersesystems.echopraxia:semantic:<VERSION>\" Basic Usage \u00b6 To set up a logger for a Person with name and age properties, you would do the following: import com.tersesystems.echopraxia.semantic.* ; SemanticLogger < Person > logger = SemanticLoggerFactory . getLogger ( getClass (), Person . class , person -> \"person.name = {}, person.age = {}\" , p -> fb -> fb . list ( fb . string ( \"name\" , p . name ), fb . number ( \"age\" , p . age ))); Person person = new Person ( \"Eloise\" , 1 ); logger . info ( person ); Conditions \u00b6 Semantic loggers take conditions in the same way that other loggers do, either through predicate: if ( logger . isInfoEnabled ( condition )) { logger . info ( person ); } or directly on the method: logger . info ( condition , person ); or on the logger: logger . withCondition ( condition ). info ( person ); Context \u00b6 Semantic loggers can add fields to context in the same way other loggers do. SemanticLogger < Person > loggerWithContext = logger . withFields ( fb -> fb . string ( \"some_context_field\" , contextValue ));","title":"Semantic Logger"},{"location":"additional/semantic/#semantic-logger","text":"Semantic Loggers are strongly typed, and will only log a particular kind of argument. All the work of field building and setting up a message is done from setup.","title":"Semantic Logger"},{"location":"additional/semantic/#installation","text":"Semantic Loggers have a dependency on the api module, but do not have any implementation dependencies. Maven: <dependency> <groupId>com.tersesystems.echopraxia</groupId> <artifactId>semantic</artifactId> <version><VERSION></version> </dependency> Gradle: implementation \"com.tersesystems.echopraxia:semantic:<VERSION>\"","title":"Installation"},{"location":"additional/semantic/#basic-usage","text":"To set up a logger for a Person with name and age properties, you would do the following: import com.tersesystems.echopraxia.semantic.* ; SemanticLogger < Person > logger = SemanticLoggerFactory . getLogger ( getClass (), Person . class , person -> \"person.name = {}, person.age = {}\" , p -> fb -> fb . list ( fb . string ( \"name\" , p . name ), fb . number ( \"age\" , p . age ))); Person person = new Person ( \"Eloise\" , 1 ); logger . info ( person );","title":"Basic Usage"},{"location":"additional/semantic/#conditions","text":"Semantic loggers take conditions in the same way that other loggers do, either through predicate: if ( logger . isInfoEnabled ( condition )) { logger . info ( person ); } or directly on the method: logger . info ( condition , person ); or on the logger: logger . withCondition ( condition ). info ( person );","title":"Conditions"},{"location":"additional/semantic/#context","text":"Semantic loggers can add fields to context in the same way other loggers do. SemanticLogger < Person > loggerWithContext = logger . withFields ( fb -> fb . string ( \"some_context_field\" , contextValue ));","title":"Context"},{"location":"frameworks/log4j2/","text":"Log4J2 Framework \u00b6 Similar to Logstash, you can get access to Log4J specific features by casting to the underlying Log4JCoreLogger class. import com.tersesystems.echopraxia.log4j.* ; import com.tersesystems.echopraxia.api.* ; Log4JCoreLogger core = ( Log4JCoreLogger ) CoreLoggerFactory . getLogger (); Marker Access \u00b6 The Log4JCoreLogger has a withMarker method that takes a Log4J marker: final Marker securityMarker = MarkerManager . getMarker ( \"SECURITY\" ); Logger < FieldBuilder > logger = LoggerFactory . getLogger ( core . withMarker ( securityMarker ), FieldBuilder . instance ); If you have a marker set as context, you can evaluate it in a condition through casting to Log4JLoggingContext : Condition hasAnyMarkers = ( level , context ) -> { Log4JLoggingContext c = ( Log4JLoggingContext ) context ; Marker m = c . getMarker (); return securityMarker . equals ( m ); }; If you need to get the Log4j logger from a core logger, you can cast and call core.logger() : Logger < PresentationFieldBuilder > baseLogger = LoggerFactory . getLogger (); Log4JCoreLogger core = ( Log4JCoreLogger ) baseLogger . core (); org . apache . logging . log4j . Logger log4jLogger = core . logger (); Direct Log4J API \u00b6 In the event that the Log4J2 API must be used directly, an EchopraxiaFieldsMessage can be sent in for JSON rendering. import com.tersesystems.echopraxia.api.FieldBuilder ; import com.tersesystems.echopraxia.api.FieldBuilderResult ; import com.tersesystems.echopraxia.log4j.layout.EchopraxiaFieldsMessage ; import org.apache.logging.log4j.LogManager ; import org.apache.logging.log4j.Logger ; FieldBuilder fb = FieldBuilder . instance (); Logger logger = LogManager . getLogger (); EchopraxiaFieldsMessage message = structured ( \"echopraxia message {}\" , fb . string ( \"foo\" , \"bar\" )); logger . info ( message ); EchopraxiaFieldsMessage structured ( String message , FieldBuilderResult args ) { List < FIeld > loggerFields = Collections . emptyList (); return new EchopraxiaFieldsMessage ( message , loggerFields , result . fields ()); } Note that exceptions must also be passed outside the message to be fully processed by Log4J: Exception e = new RuntimeException (); EchopraxiaFieldsMessage message = structured ( \"exception {}\" , fb . exception ( e )); logger . info ( message , e ); Unfortunately, I don't understand Log4J internals well enough to make conditions work using the Log4J API. One option could be to write a Log4J Filter to work on a message.","title":"Log4J2 Framework"},{"location":"frameworks/log4j2/#log4j2-framework","text":"Similar to Logstash, you can get access to Log4J specific features by casting to the underlying Log4JCoreLogger class. import com.tersesystems.echopraxia.log4j.* ; import com.tersesystems.echopraxia.api.* ; Log4JCoreLogger core = ( Log4JCoreLogger ) CoreLoggerFactory . getLogger ();","title":"Log4J2 Framework"},{"location":"frameworks/log4j2/#marker-access","text":"The Log4JCoreLogger has a withMarker method that takes a Log4J marker: final Marker securityMarker = MarkerManager . getMarker ( \"SECURITY\" ); Logger < FieldBuilder > logger = LoggerFactory . getLogger ( core . withMarker ( securityMarker ), FieldBuilder . instance ); If you have a marker set as context, you can evaluate it in a condition through casting to Log4JLoggingContext : Condition hasAnyMarkers = ( level , context ) -> { Log4JLoggingContext c = ( Log4JLoggingContext ) context ; Marker m = c . getMarker (); return securityMarker . equals ( m ); }; If you need to get the Log4j logger from a core logger, you can cast and call core.logger() : Logger < PresentationFieldBuilder > baseLogger = LoggerFactory . getLogger (); Log4JCoreLogger core = ( Log4JCoreLogger ) baseLogger . core (); org . apache . logging . log4j . Logger log4jLogger = core . logger ();","title":"Marker Access"},{"location":"frameworks/log4j2/#direct-log4j-api","text":"In the event that the Log4J2 API must be used directly, an EchopraxiaFieldsMessage can be sent in for JSON rendering. import com.tersesystems.echopraxia.api.FieldBuilder ; import com.tersesystems.echopraxia.api.FieldBuilderResult ; import com.tersesystems.echopraxia.log4j.layout.EchopraxiaFieldsMessage ; import org.apache.logging.log4j.LogManager ; import org.apache.logging.log4j.Logger ; FieldBuilder fb = FieldBuilder . instance (); Logger logger = LogManager . getLogger (); EchopraxiaFieldsMessage message = structured ( \"echopraxia message {}\" , fb . string ( \"foo\" , \"bar\" )); logger . info ( message ); EchopraxiaFieldsMessage structured ( String message , FieldBuilderResult args ) { List < FIeld > loggerFields = Collections . emptyList (); return new EchopraxiaFieldsMessage ( message , loggerFields , result . fields ()); } Note that exceptions must also be passed outside the message to be fully processed by Log4J: Exception e = new RuntimeException (); EchopraxiaFieldsMessage message = structured ( \"exception {}\" , fb . exception ( e )); logger . info ( message , e ); Unfortunately, I don't understand Log4J internals well enough to make conditions work using the Log4J API. One option could be to write a Log4J Filter to work on a message.","title":"Direct Log4J API"},{"location":"frameworks/logback/","text":"Logstash Framework \u00b6 You can get access to the Logback and Logstash features by casting. First, import the logstash package. This gets you access to the CoreLoggerFactory and CoreLogger , which can be cast to LogstashCoreLogger : import com.tersesystems.echopraxia.logstash.* ; import com.tersesystems.echopraxia.api.* ; LogstashCoreLogger core = ( LogstashCoreLogger ) CoreLoggerFactory . getLogger (); Markers \u00b6 The LogstashCoreLogger has a withMarkers method that takes an SLF4J marker: Logger < FieldBuilder > logger = LoggerFactory . getLogger ( core . withMarkers ( MarkerFactory . getMarker ( \"SECURITY\" )), FieldBuilder . instance ); If you have markers set as context, you can evaluate them in a condition through casting to LogstashLoggingContext : Condition hasAnyMarkers = ( level , context ) -> { LogstashLoggingContext c = ( LogstashLoggingContext ) context ; List < org . slf4j . Marker > markers = c . getMarkers (); return markers . size () > 0 ; }; If you need to get at the SLF4J logger from a core logger, you can cast and call core.logger() : Logger baseLogger = LoggerFactory . getLogger (); LogstashCoreLogger core = ( LogstashCoreLogger ) baseLogger . core (); org . slf4j . Logger slf4jLogger = core . logger (); Direct Logback / SLF4J API \u00b6 There will be times when the application uses an SLF4J logger, and it's not feasible to use an Echopraxia Logger. This is not a problem: you can pass Echopraxia fields directly as arguments through SLF4J, and they will be rendered as expected. You'll need to have a field builder in scope: FieldBuilder fb = FieldBuilder . instance (); org . slf4j . Logger slf4jLogger = org . slf4j . LoggerFactory . getLogger ( \"com.example.Main\" ); slf4jLogger . info ( \"SLF4J message {}\" , fb . string ( \"foo\" , \"bar\" )); You can pass arguments in either individually (do not use fb.list ): slf4jLogger . info ( \"SLF4J message string {} number {}\" , fb . string ( \"foo\" , \"bar\" ), fb . number ( \"count\" , 1 )); Note that if you want to use exceptions in conditions, you pass exceptions through twice, once for the argument and again for the exception itself -- it must be the last argument, and must not have a message parameter to register as an exception (this is the SLF4J convention, it will eat exceptions otherwise): Exception e = new RuntimeException (); slf4jLogger . error ( \"SLF4J exception {}\" , fb . exception ( e ), e ); SLF4J has no direct support for conditions, but we can fake it with a ConditionMarker : import com.tersesystems.echopraxia.logback.* ; Marker marker = ConditionMarker . apply ( condition ); slf4jLogger . info ( marker , \"SLF4J message string {} number {}\" , fb . string ( \"foo\" , \"bar\" ), fb . number ( \"count\" , 1 )); You may want to represent session specific information as \"logger context\" field, which correspond to logstash markers. If you want to use a context field, you can wrap a field in FieldMarker and then pass it in directly or use Markers.aggregate with a condition: FieldBuilder fb = FieldBuilder . instance (); FieldMarker fields = FieldMarker . apply ( fb . list ( fb . string ( \"sessionId\" , \"value\" ), fb . number ( \"correlationId\" , 1 ) ) ); ConditionMarker conditionMarker = ConditionMarker . apply ( Condition . stringMatch ( \"sessionId\" , s -> s . raw (). equals ( \"value\" ))) ); logger . info ( Markers . aggregate ( fieldMarker , conditionMarker ), \"condition and marker\" ); To integrate this with Logback, you will need to have a ConditionTurboFilter which will evaluate conditions wrapped in ConditionMarker , and a LogstashFieldAppender that turns the fields into logstash markers and structured arguments for use with LogstashEncoder (note that this directly mutates the logging event, so don't have multiple async appenders going on with this): <configuration> <!-- logback.xml --> <!-- evaluates conditions --> <turboFilter class= \"com.tersesystems.echopraxia.logback.ConditionTurboFilter\" /> <appender name= \"ASYNC_JSON\" class= \"net.logstash.logback.appender.LoggingEventAsyncDisruptorAppender\" > <!-- replaces fields with logstash markers and structured arguments --> <appender class= \"com.tersesystems.echopraxia.logstash.LogstashFieldAppender\" > <appender class= \"ch.qos.logback.core.FileAppender\" > <file> application.log </file> <encoder class= \"net.logstash.logback.encoder.LogstashEncoder\" /> </appender> </appender> </appender> <root level= \"INFO\" > <appender-ref ref= \"ASYNC_JSON\" /> </root> </configuration> Logback Converters \u00b6 If you want to extract some fields directly in a line oriented context, you can use FieldConverter , ArgumentFieldConverter , or LoggerFieldConverter to extract fields using a JSON path. For example, if you log something with a field called book : logger . info ( \"{}\" , fb -> fb . string ( \"book\" , \"Interesting Book\" )); Then you can use %fields{$.book} to extract the book field from the event and render it. In most cases you will want to use FieldConverter , which searches for fields in both arguments and logger context, but if you want to isolate for one or the other, you can respectively use ArgumentFieldConverter or LoggerFieldConverter . <configuration> <!-- Search both arguments and context, arguments takes precedence --> <conversionRule conversionWord= \"fields\" converterClass= \"com.tersesystems.echopraxia.logback.FieldConverter\" /> <!-- Search fields defined as arguments logger.info(\"{}\", fb -> ...) --> <conversionRule conversionWord= \"argctx\" converterClass= \"com.tersesystems.echopraxia.logback.ArgumentFieldConverter\" /> <!-- Search fields defined in logger.withFields(...) --> <conversionRule conversionWord= \"loggerctx\" converterClass= \"com.tersesystems.echopraxia.logback.LoggerFieldConverter\" /> <root> <appender name= \"STDOUT\" class= \"ch.qos.logback.core.ConsoleAppender\" > <encoder> <pattern> %-4relative [%thread] %-5level [%fields{$.book}] [%loggerctx{$.book}] [%argctx{$.book}] %logger - %msg%n </pattern> </encoder> </appender> </root> </configuration>","title":"Logback Framework"},{"location":"frameworks/logback/#logstash-framework","text":"You can get access to the Logback and Logstash features by casting. First, import the logstash package. This gets you access to the CoreLoggerFactory and CoreLogger , which can be cast to LogstashCoreLogger : import com.tersesystems.echopraxia.logstash.* ; import com.tersesystems.echopraxia.api.* ; LogstashCoreLogger core = ( LogstashCoreLogger ) CoreLoggerFactory . getLogger ();","title":"Logstash Framework"},{"location":"frameworks/logback/#markers","text":"The LogstashCoreLogger has a withMarkers method that takes an SLF4J marker: Logger < FieldBuilder > logger = LoggerFactory . getLogger ( core . withMarkers ( MarkerFactory . getMarker ( \"SECURITY\" )), FieldBuilder . instance ); If you have markers set as context, you can evaluate them in a condition through casting to LogstashLoggingContext : Condition hasAnyMarkers = ( level , context ) -> { LogstashLoggingContext c = ( LogstashLoggingContext ) context ; List < org . slf4j . Marker > markers = c . getMarkers (); return markers . size () > 0 ; }; If you need to get at the SLF4J logger from a core logger, you can cast and call core.logger() : Logger baseLogger = LoggerFactory . getLogger (); LogstashCoreLogger core = ( LogstashCoreLogger ) baseLogger . core (); org . slf4j . Logger slf4jLogger = core . logger ();","title":"Markers"},{"location":"frameworks/logback/#direct-logback-slf4j-api","text":"There will be times when the application uses an SLF4J logger, and it's not feasible to use an Echopraxia Logger. This is not a problem: you can pass Echopraxia fields directly as arguments through SLF4J, and they will be rendered as expected. You'll need to have a field builder in scope: FieldBuilder fb = FieldBuilder . instance (); org . slf4j . Logger slf4jLogger = org . slf4j . LoggerFactory . getLogger ( \"com.example.Main\" ); slf4jLogger . info ( \"SLF4J message {}\" , fb . string ( \"foo\" , \"bar\" )); You can pass arguments in either individually (do not use fb.list ): slf4jLogger . info ( \"SLF4J message string {} number {}\" , fb . string ( \"foo\" , \"bar\" ), fb . number ( \"count\" , 1 )); Note that if you want to use exceptions in conditions, you pass exceptions through twice, once for the argument and again for the exception itself -- it must be the last argument, and must not have a message parameter to register as an exception (this is the SLF4J convention, it will eat exceptions otherwise): Exception e = new RuntimeException (); slf4jLogger . error ( \"SLF4J exception {}\" , fb . exception ( e ), e ); SLF4J has no direct support for conditions, but we can fake it with a ConditionMarker : import com.tersesystems.echopraxia.logback.* ; Marker marker = ConditionMarker . apply ( condition ); slf4jLogger . info ( marker , \"SLF4J message string {} number {}\" , fb . string ( \"foo\" , \"bar\" ), fb . number ( \"count\" , 1 )); You may want to represent session specific information as \"logger context\" field, which correspond to logstash markers. If you want to use a context field, you can wrap a field in FieldMarker and then pass it in directly or use Markers.aggregate with a condition: FieldBuilder fb = FieldBuilder . instance (); FieldMarker fields = FieldMarker . apply ( fb . list ( fb . string ( \"sessionId\" , \"value\" ), fb . number ( \"correlationId\" , 1 ) ) ); ConditionMarker conditionMarker = ConditionMarker . apply ( Condition . stringMatch ( \"sessionId\" , s -> s . raw (). equals ( \"value\" ))) ); logger . info ( Markers . aggregate ( fieldMarker , conditionMarker ), \"condition and marker\" ); To integrate this with Logback, you will need to have a ConditionTurboFilter which will evaluate conditions wrapped in ConditionMarker , and a LogstashFieldAppender that turns the fields into logstash markers and structured arguments for use with LogstashEncoder (note that this directly mutates the logging event, so don't have multiple async appenders going on with this): <configuration> <!-- logback.xml --> <!-- evaluates conditions --> <turboFilter class= \"com.tersesystems.echopraxia.logback.ConditionTurboFilter\" /> <appender name= \"ASYNC_JSON\" class= \"net.logstash.logback.appender.LoggingEventAsyncDisruptorAppender\" > <!-- replaces fields with logstash markers and structured arguments --> <appender class= \"com.tersesystems.echopraxia.logstash.LogstashFieldAppender\" > <appender class= \"ch.qos.logback.core.FileAppender\" > <file> application.log </file> <encoder class= \"net.logstash.logback.encoder.LogstashEncoder\" /> </appender> </appender> </appender> <root level= \"INFO\" > <appender-ref ref= \"ASYNC_JSON\" /> </root> </configuration>","title":"Direct Logback / SLF4J API"},{"location":"frameworks/logback/#logback-converters","text":"If you want to extract some fields directly in a line oriented context, you can use FieldConverter , ArgumentFieldConverter , or LoggerFieldConverter to extract fields using a JSON path. For example, if you log something with a field called book : logger . info ( \"{}\" , fb -> fb . string ( \"book\" , \"Interesting Book\" )); Then you can use %fields{$.book} to extract the book field from the event and render it. In most cases you will want to use FieldConverter , which searches for fields in both arguments and logger context, but if you want to isolate for one or the other, you can respectively use ArgumentFieldConverter or LoggerFieldConverter . <configuration> <!-- Search both arguments and context, arguments takes precedence --> <conversionRule conversionWord= \"fields\" converterClass= \"com.tersesystems.echopraxia.logback.FieldConverter\" /> <!-- Search fields defined as arguments logger.info(\"{}\", fb -> ...) --> <conversionRule conversionWord= \"argctx\" converterClass= \"com.tersesystems.echopraxia.logback.ArgumentFieldConverter\" /> <!-- Search fields defined in logger.withFields(...) --> <conversionRule conversionWord= \"loggerctx\" converterClass= \"com.tersesystems.echopraxia.logback.LoggerFieldConverter\" /> <root> <appender name= \"STDOUT\" class= \"ch.qos.logback.core.ConsoleAppender\" > <encoder> <pattern> %-4relative [%thread] %-5level [%fields{$.book}] [%loggerctx{$.book}] [%argctx{$.book}] %logger - %msg%n </pattern> </encoder> </appender> </root> </configuration>","title":"Logback Converters"},{"location":"usage/basics/","text":"Basic Usage \u00b6 Echopraxia is simple and easy to use, and looks very similar to SLF4J. Add the import: import com.tersesystems.echopraxia.* ; Define a logger (usually in a controller or singleton -- getClass() is particularly useful for abstract controllers): final Logger < PresentationFieldBuilder > basicLogger = LoggerFactory . getLogger ( getClass ()); Logging simple messages and exceptions are done as in SLF4J: try { ... basicLogger . info ( \"Simple message\" ); } catch ( Exception e ) { basicLogger . error ( \"Error message\" , e ); } However, when you log arguments, you pass a function which provides you with a field builder and returns a FieldBuilderResult -- a Field is a FieldBuilderResult , so you can do: basicLogger . info ( \"Message name {}\" , fb -> fb . string ( \"name\" , \"value\" )); If you are returning multiple fields, then using fb.list will return a FieldBuilderResult : basicLogger . info ( \"Message name {} age {}\" , fb -> fb . list ( fb . string ( \"name\" , \"value\" ), fb . number ( \"age\" , 13 ) )); And fb.list can take many inputs as needed, for example a stream: String [] basicLogger . info ( \"Message name {}\" , fb -> { Stream < Field > fieldStream = ...; return fb . list ( arrayOfFields ); }); You can log multiple arguments and include the exception if you want the stack trace: basicLogger . info ( \"Message name {}\" , fb -> fb . list ( fb . string ( \"name\" , \"value\" ), fb . exception ( e ) )); In older versions, fb.only() was required to convert a Field -- this is no longer required, but a FieldBuilderWithOnly interface is available to maintain those methods. Note that unlike SLF4J, you don't have to worry about including the exception as an argument \"swallowing\" the stacktrace. If an exception is present, it's always applied to the underlying logger.","title":"Basics"},{"location":"usage/basics/#basic-usage","text":"Echopraxia is simple and easy to use, and looks very similar to SLF4J. Add the import: import com.tersesystems.echopraxia.* ; Define a logger (usually in a controller or singleton -- getClass() is particularly useful for abstract controllers): final Logger < PresentationFieldBuilder > basicLogger = LoggerFactory . getLogger ( getClass ()); Logging simple messages and exceptions are done as in SLF4J: try { ... basicLogger . info ( \"Simple message\" ); } catch ( Exception e ) { basicLogger . error ( \"Error message\" , e ); } However, when you log arguments, you pass a function which provides you with a field builder and returns a FieldBuilderResult -- a Field is a FieldBuilderResult , so you can do: basicLogger . info ( \"Message name {}\" , fb -> fb . string ( \"name\" , \"value\" )); If you are returning multiple fields, then using fb.list will return a FieldBuilderResult : basicLogger . info ( \"Message name {} age {}\" , fb -> fb . list ( fb . string ( \"name\" , \"value\" ), fb . number ( \"age\" , 13 ) )); And fb.list can take many inputs as needed, for example a stream: String [] basicLogger . info ( \"Message name {}\" , fb -> { Stream < Field > fieldStream = ...; return fb . list ( arrayOfFields ); }); You can log multiple arguments and include the exception if you want the stack trace: basicLogger . info ( \"Message name {}\" , fb -> fb . list ( fb . string ( \"name\" , \"value\" ), fb . exception ( e ) )); In older versions, fb.only() was required to convert a Field -- this is no longer required, but a FieldBuilderWithOnly interface is available to maintain those methods. Note that unlike SLF4J, you don't have to worry about including the exception as an argument \"swallowing\" the stacktrace. If an exception is present, it's always applied to the underlying logger.","title":"Basic Usage"},{"location":"usage/conditions/","text":"Conditions \u00b6 Logging conditions can be handled gracefully using Condition functions. A Condition will take a Level and a LoggingContext which will return the fields of the logger. final Condition errorCondition = new Condition () { @Override public boolean test ( Level level , LoggingContext context ) { return level . equals ( Level . ERROR ); } }; Conditions can be used either on the logger, on the statement, or against the predicate check. There are two elemental conditions, Condition.always() and Condition.never() . Echopraxia has optimizations for conditions; it will treat Condition.always() as a no-op, and return a NeverLogger that has no operations for logging. The JVM can recognize that logging has no effect at all, and will eliminate the method call as dead code . Conditions are a great way to manage diagnostic logging in your application with more flexibility than global log levels can provide. Consider enabling setting your application logging to DEBUG i.e. <logger name=\"your.application.package\" level=\"DEBUG\"/> and using conditions to turn on and off debugging as needed . Conditions come with and , or , and xor functionality, and can provide more precise and expressive logging criteria than can be managed with filters and markers. This is particularly useful when combined with filters . For example, if you want to have logging that only activates during business hours, you can use the following: import com.tersesystems.echopraxia.Condition ; public class MyBusinessConditions { private static final Clock officeClock = Clock . system ( ZoneId . of ( \"America/Los_Angeles\" )) ; public Condition businessHoursOnly () { return Condition . operational (). and ( weekdays (). and ( from9to5 ())); } public Condition weekdays () { return ( level , context ) -> { LocalDate now = LocalDate . now ( officeClock ); final DayOfWeek dayOfWeek = now . getDayOfWeek (); return ! ( dayOfWeek . equals ( DayOfWeek . SATURDAY ) || dayOfWeek . equals ( DayOfWeek . SUNDAY )); }; } public Condition from9to5 () { return ( level , context ) -> LocalTime . now ( officeClock ). query ( temporal -> { // hour is zero based, so adjust for readability final int hour = temporal . get ( ChronoField . HOUR_OF_DAY ) + 1 ; return ( hour >= 9 ) && ( hour <= 17 ); // 8 am to 5 pm }); } } Matching values is best done using Value.equals in conjunction with one of the match methods: // Better type safety using Value.equals Condition hasDerp = Condition . stringMatch ( \"herp\" , v -> Value . equals ( v , Value . string ( \"herp\" ))) // this works too Condition logins = Condition . numberMatch ( \"logins\" , v -> v . equals ( number ( 1 ))); The context parameter that is passed in is a LoggingContext that contains the argument fields, the fields added directly to the logger, and a reference to the CoreLogger , which can return useful context like the logger name. This is only a part of the available functionality in conditions. You can tie conditions directly to a backend, such as a database or key/value store, or trigger them to work in response to an exception or unusual metrics. See the redis example , jmx example , metrics example , and timed diagnostic example . JSON Path \u00b6 In situations where you're looking through fields for a condition, you can use JSONPath to find values from the logging context in a condition. Tip: if you are using IntelliJ IDEA, you can add the @Language(\"JSONPath\") annotation to inject JSONPATH . The context.find* methods take a class as a type, and a JSON path , which can be used to search through context fields (or arguments, if the condition is used in a logging statement). The basic types are String , the Number subclasses such as Integer , and Boolean . If no matching path is found, an empty Optional is returned. Optional < String > optName = context . findString ( \"$.person.name\" ); This also applies to Throwable which are usually passed in as arguments: Optional < Throwable > optThrowable = context . findThrowable (); You can treat a Throwable as a JSON object, i.e. the following will all work with the default $.exception path: Optional < String > className = ctx . findString ( \"$.exception.className\" ); Optional < String > message = ctx . findString ( \"$.exception.message\" ); Optional < Throwable > cause = ctx . findThrowable ( \"$.exception.cause\" ); And you can also query stack trace elements: Optional < Map < String , ?>> stacktraceElement = ctx . findObject ( \"$.exception.stackTrace[0]\" ) Optional < String > methodName = ctx . findString ( \"$.exception.stackTrace[0].methodName\" ); Optional < List <?>> listOfElements = ctx . findObject ( \"$.exception.stackTrace[5..10]\" ) Finding an explicitly null value returns a boolean : // fb.nullValue(\"keyWithNullValue\") sets an explicitly null value boolean isNull = context . findNull ( \"$.keyWithNullValue\" ); Finding an object will return a Map : Optional < Map < String , ?>> mother = context . findObject ( \"$.person.mother\" ); For a List , in the case of an array value or when using indefinite queries: List < String > interests = context . findList ( \"$.person.mother.interests\" ); You can use inline predicates , which will return a List of the results: final Condition cheapBookCondition = ( level , context ) -> ! context . findList ( \"$.store.book[?(@.price < 10)]\" ). isEmpty (); The inline and filter predicates are not available for exceptions. Instead, you must use filter : class FindException { void logException () { Condition throwableCondition = ( level , ctx ) -> ctx . findThrowable () . filter ( e -> \"test message\" . equals ( e . getMessage ())) . isPresent (); logger . error ( throwableCondition , \"Error message\" , new RuntimeException ( \"test message\" )); } } There are many more options available using JSONPath. You can try out the online evaluator to test out expressions. Logger \u00b6 You can use conditions in a logger, and statements will only log if the condition is met: var loggerWithCondition = logger . withCondition ( condition ); You can also build up conditions: Logger < PresentationFieldBuilder > loggerWithAandB = logger . withCondition ( conditionA ). withCondition ( conditionB ); Conditions are only evaluated once a level/marker check is passed, so something like loggerWithAandB . trace ( \"some message\" ); will short circuit on the level check before any condition is reached. Conditions look for fields, but those fields can come from either context or argument. For example, the following condition will log because the condition finds an argument field: Condition cond = ( level , ctx ) -> ctx . findString ( \"somename\" ). isPresent (); logger . withCondition ( cond ). info ( \"some message\" , fb -> fb . string ( \"somename\" , \"somevalue\" )); // matches argument Statement \u00b6 You can also use conditions in an individual statement: logger . info ( mustHaveFoo , \"Only log if foo is present\" ); Predicates \u00b6 Conditions can also be used in predicate blocks for expensive objects. if ( logger . isInfoEnabled ( condition )) { // only true if condition and is info } Conditions will only be checked after an isEnabled check is passed -- the level (and optional marker) is always checked first, before any conditions. A condition may also evaluate context fields that are set in a logger: // Conditions may evaluate context Condition cond = ( level , ctx ) -> ctx . findString ( \"somename\" ). isPresent (); boolean loggerEnabled = logger . withFields ( fb -> fb . string ( \"somename\" , \"somevalue\" )) . withCondition ( condition ) . isInfoEnabled (); Using a predicate with a condition does not trigger any logging, so it can be a nice way to \"dry run\" a condition. Note that the context evaluation takes place every time a condition is run, so doing something like this is not good: var loggerWithContextAndCondition = logger . withFields ( fb -> fb . string ( \"somename\" , \"somevalue\" )) . withCondition ( condition ); // check evaluates context if ( loggerWithContextAndCondition . isInfoEnabled ()) { // info statement _also_ evaluates context loggerWithContextAndCondition . info ( \"some message\" ); } This results in the context being evaluated both in the block and in the info statement itself, which is inefficient. It is generally preferable to pass in a condition explicitly on the statement, as it will only evaluate once. var loggerWithContext = logger . withFields ( fb -> fb . string ( \"somename\" , \"somevalue\" )) loggerWithContext . info ( condition , \"message\" ); or just on the statement. loggerWithContextAndCondition . info ( \"some message\" );","title":"Conditions"},{"location":"usage/conditions/#conditions","text":"Logging conditions can be handled gracefully using Condition functions. A Condition will take a Level and a LoggingContext which will return the fields of the logger. final Condition errorCondition = new Condition () { @Override public boolean test ( Level level , LoggingContext context ) { return level . equals ( Level . ERROR ); } }; Conditions can be used either on the logger, on the statement, or against the predicate check. There are two elemental conditions, Condition.always() and Condition.never() . Echopraxia has optimizations for conditions; it will treat Condition.always() as a no-op, and return a NeverLogger that has no operations for logging. The JVM can recognize that logging has no effect at all, and will eliminate the method call as dead code . Conditions are a great way to manage diagnostic logging in your application with more flexibility than global log levels can provide. Consider enabling setting your application logging to DEBUG i.e. <logger name=\"your.application.package\" level=\"DEBUG\"/> and using conditions to turn on and off debugging as needed . Conditions come with and , or , and xor functionality, and can provide more precise and expressive logging criteria than can be managed with filters and markers. This is particularly useful when combined with filters . For example, if you want to have logging that only activates during business hours, you can use the following: import com.tersesystems.echopraxia.Condition ; public class MyBusinessConditions { private static final Clock officeClock = Clock . system ( ZoneId . of ( \"America/Los_Angeles\" )) ; public Condition businessHoursOnly () { return Condition . operational (). and ( weekdays (). and ( from9to5 ())); } public Condition weekdays () { return ( level , context ) -> { LocalDate now = LocalDate . now ( officeClock ); final DayOfWeek dayOfWeek = now . getDayOfWeek (); return ! ( dayOfWeek . equals ( DayOfWeek . SATURDAY ) || dayOfWeek . equals ( DayOfWeek . SUNDAY )); }; } public Condition from9to5 () { return ( level , context ) -> LocalTime . now ( officeClock ). query ( temporal -> { // hour is zero based, so adjust for readability final int hour = temporal . get ( ChronoField . HOUR_OF_DAY ) + 1 ; return ( hour >= 9 ) && ( hour <= 17 ); // 8 am to 5 pm }); } } Matching values is best done using Value.equals in conjunction with one of the match methods: // Better type safety using Value.equals Condition hasDerp = Condition . stringMatch ( \"herp\" , v -> Value . equals ( v , Value . string ( \"herp\" ))) // this works too Condition logins = Condition . numberMatch ( \"logins\" , v -> v . equals ( number ( 1 ))); The context parameter that is passed in is a LoggingContext that contains the argument fields, the fields added directly to the logger, and a reference to the CoreLogger , which can return useful context like the logger name. This is only a part of the available functionality in conditions. You can tie conditions directly to a backend, such as a database or key/value store, or trigger them to work in response to an exception or unusual metrics. See the redis example , jmx example , metrics example , and timed diagnostic example .","title":"Conditions"},{"location":"usage/conditions/#json-path","text":"In situations where you're looking through fields for a condition, you can use JSONPath to find values from the logging context in a condition. Tip: if you are using IntelliJ IDEA, you can add the @Language(\"JSONPath\") annotation to inject JSONPATH . The context.find* methods take a class as a type, and a JSON path , which can be used to search through context fields (or arguments, if the condition is used in a logging statement). The basic types are String , the Number subclasses such as Integer , and Boolean . If no matching path is found, an empty Optional is returned. Optional < String > optName = context . findString ( \"$.person.name\" ); This also applies to Throwable which are usually passed in as arguments: Optional < Throwable > optThrowable = context . findThrowable (); You can treat a Throwable as a JSON object, i.e. the following will all work with the default $.exception path: Optional < String > className = ctx . findString ( \"$.exception.className\" ); Optional < String > message = ctx . findString ( \"$.exception.message\" ); Optional < Throwable > cause = ctx . findThrowable ( \"$.exception.cause\" ); And you can also query stack trace elements: Optional < Map < String , ?>> stacktraceElement = ctx . findObject ( \"$.exception.stackTrace[0]\" ) Optional < String > methodName = ctx . findString ( \"$.exception.stackTrace[0].methodName\" ); Optional < List <?>> listOfElements = ctx . findObject ( \"$.exception.stackTrace[5..10]\" ) Finding an explicitly null value returns a boolean : // fb.nullValue(\"keyWithNullValue\") sets an explicitly null value boolean isNull = context . findNull ( \"$.keyWithNullValue\" ); Finding an object will return a Map : Optional < Map < String , ?>> mother = context . findObject ( \"$.person.mother\" ); For a List , in the case of an array value or when using indefinite queries: List < String > interests = context . findList ( \"$.person.mother.interests\" ); You can use inline predicates , which will return a List of the results: final Condition cheapBookCondition = ( level , context ) -> ! context . findList ( \"$.store.book[?(@.price < 10)]\" ). isEmpty (); The inline and filter predicates are not available for exceptions. Instead, you must use filter : class FindException { void logException () { Condition throwableCondition = ( level , ctx ) -> ctx . findThrowable () . filter ( e -> \"test message\" . equals ( e . getMessage ())) . isPresent (); logger . error ( throwableCondition , \"Error message\" , new RuntimeException ( \"test message\" )); } } There are many more options available using JSONPath. You can try out the online evaluator to test out expressions.","title":"JSON Path"},{"location":"usage/conditions/#logger","text":"You can use conditions in a logger, and statements will only log if the condition is met: var loggerWithCondition = logger . withCondition ( condition ); You can also build up conditions: Logger < PresentationFieldBuilder > loggerWithAandB = logger . withCondition ( conditionA ). withCondition ( conditionB ); Conditions are only evaluated once a level/marker check is passed, so something like loggerWithAandB . trace ( \"some message\" ); will short circuit on the level check before any condition is reached. Conditions look for fields, but those fields can come from either context or argument. For example, the following condition will log because the condition finds an argument field: Condition cond = ( level , ctx ) -> ctx . findString ( \"somename\" ). isPresent (); logger . withCondition ( cond ). info ( \"some message\" , fb -> fb . string ( \"somename\" , \"somevalue\" )); // matches argument","title":"Logger"},{"location":"usage/conditions/#statement","text":"You can also use conditions in an individual statement: logger . info ( mustHaveFoo , \"Only log if foo is present\" );","title":"Statement"},{"location":"usage/conditions/#predicates","text":"Conditions can also be used in predicate blocks for expensive objects. if ( logger . isInfoEnabled ( condition )) { // only true if condition and is info } Conditions will only be checked after an isEnabled check is passed -- the level (and optional marker) is always checked first, before any conditions. A condition may also evaluate context fields that are set in a logger: // Conditions may evaluate context Condition cond = ( level , ctx ) -> ctx . findString ( \"somename\" ). isPresent (); boolean loggerEnabled = logger . withFields ( fb -> fb . string ( \"somename\" , \"somevalue\" )) . withCondition ( condition ) . isInfoEnabled (); Using a predicate with a condition does not trigger any logging, so it can be a nice way to \"dry run\" a condition. Note that the context evaluation takes place every time a condition is run, so doing something like this is not good: var loggerWithContextAndCondition = logger . withFields ( fb -> fb . string ( \"somename\" , \"somevalue\" )) . withCondition ( condition ); // check evaluates context if ( loggerWithContextAndCondition . isInfoEnabled ()) { // info statement _also_ evaluates context loggerWithContextAndCondition . info ( \"some message\" ); } This results in the context being evaluated both in the block and in the info statement itself, which is inefficient. It is generally preferable to pass in a condition explicitly on the statement, as it will only evaluate once. var loggerWithContext = logger . withFields ( fb -> fb . string ( \"somename\" , \"somevalue\" )) loggerWithContext . info ( condition , \"message\" ); or just on the statement. loggerWithContextAndCondition . info ( \"some message\" );","title":"Predicates"},{"location":"usage/context/","text":"Context \u00b6 You can also add fields directly to the logger using logger.withFields for contextual logging: var loggerWithFoo = basicLogger . withFields ( fb -> fb . string ( \"foo\" , \"bar\" )); // will log \"foo\": \"bar\" field in a JSON appender. loggerWithFoo . info ( \"JSON field will log automatically\" ) This works very well for HTTP session and request data such as correlation ids. One thing to be aware of that the popular idiom of using public static final Logger<MyFieldBuilder> logger can be limiting in cases where you want to include context data. For example, if you have a number of objects with their own internal state, it may be more appropriate to create a logger field on the object. public class PlayerData { // the date is scoped to an instance of this player private Date lastAccessedDate = new Date (); // logger is not static because lastAccessedDate is an instance variable private final Logger < BuilderWithDate > logger = LoggerFactory . getLogger () . withFieldBuilder ( BuilderWithDate . class ) . withFields ( fb -> fb . date ( \"last_accessed_date\" , lastAccessedDate )); } Because values may be tied to state or variables that can change between method calls, the function call made by withFields is call by name i.e. the function is called on every logging statement for evaluation against any conditions and the logging statement will contain whatever the current value of lastAccessedDate at evaluation. It's important to note that context evaluation only happens after enabled checks. For example, isInfoEnabled will not trigger context evaluation by itself. However, any implementation specific markers attached to the context will be passed in for the enabled check, as both Logback and Log4J incorporate marker checks in isEnabled . // will not evaluate context fields // will evaluate any impl-specific markers (Logback or Log4J) boolean enabled = logger . isInfoEnabled (); The way that context works in conjunction with conditions is more involved, and is covered in the conditions section. Thread Context \u00b6 You can also resolve any fields in Mapped Diagnostic Context (MDC) into fields, using logger.withThreadContext() . This method provides a pre-built function that calls fb.string for each entry in the map. Because MDC is thread local, if you pass the logger between threads or use asynchronous processing i.e. CompletionStage/CompletableFuture , you may have inconsistent results. org . slf4j . MDC . put ( \"mdckey\" , \"mdcvalue\" ); myLogger . withThreadContext (). info ( \"This statement has MDC values in context\" ); This method is call by name, and so will provide the MDC state as fields at the time the logging statement is evaluated. Thread Safety \u00b6 Thread safety is something to be aware of when using context fields. While fields are thread-safe and using a context is far more convenient than using MDC, you do still have to be aware when you are accessing non-thread safe state. For example, SimpleDateFormat is infamously not thread-safe, and so the following code is not safe to use in a multi-threaded context: private final static DateFormat df = new SimpleDateFormat ( \"yyyyMMdd\" ); // UNSAFE EXAMPLE private static final Logger < PresentationFieldBuilder > logger = LoggerFactory . getLogger () . withFields ( fb -> fb . string ( \"unsafe_date\" , df . format ( new Date ())));","title":"Context"},{"location":"usage/context/#context","text":"You can also add fields directly to the logger using logger.withFields for contextual logging: var loggerWithFoo = basicLogger . withFields ( fb -> fb . string ( \"foo\" , \"bar\" )); // will log \"foo\": \"bar\" field in a JSON appender. loggerWithFoo . info ( \"JSON field will log automatically\" ) This works very well for HTTP session and request data such as correlation ids. One thing to be aware of that the popular idiom of using public static final Logger<MyFieldBuilder> logger can be limiting in cases where you want to include context data. For example, if you have a number of objects with their own internal state, it may be more appropriate to create a logger field on the object. public class PlayerData { // the date is scoped to an instance of this player private Date lastAccessedDate = new Date (); // logger is not static because lastAccessedDate is an instance variable private final Logger < BuilderWithDate > logger = LoggerFactory . getLogger () . withFieldBuilder ( BuilderWithDate . class ) . withFields ( fb -> fb . date ( \"last_accessed_date\" , lastAccessedDate )); } Because values may be tied to state or variables that can change between method calls, the function call made by withFields is call by name i.e. the function is called on every logging statement for evaluation against any conditions and the logging statement will contain whatever the current value of lastAccessedDate at evaluation. It's important to note that context evaluation only happens after enabled checks. For example, isInfoEnabled will not trigger context evaluation by itself. However, any implementation specific markers attached to the context will be passed in for the enabled check, as both Logback and Log4J incorporate marker checks in isEnabled . // will not evaluate context fields // will evaluate any impl-specific markers (Logback or Log4J) boolean enabled = logger . isInfoEnabled (); The way that context works in conjunction with conditions is more involved, and is covered in the conditions section.","title":"Context"},{"location":"usage/context/#thread-context","text":"You can also resolve any fields in Mapped Diagnostic Context (MDC) into fields, using logger.withThreadContext() . This method provides a pre-built function that calls fb.string for each entry in the map. Because MDC is thread local, if you pass the logger between threads or use asynchronous processing i.e. CompletionStage/CompletableFuture , you may have inconsistent results. org . slf4j . MDC . put ( \"mdckey\" , \"mdcvalue\" ); myLogger . withThreadContext (). info ( \"This statement has MDC values in context\" ); This method is call by name, and so will provide the MDC state as fields at the time the logging statement is evaluated.","title":"Thread Context"},{"location":"usage/context/#thread-safety","text":"Thread safety is something to be aware of when using context fields. While fields are thread-safe and using a context is far more convenient than using MDC, you do still have to be aware when you are accessing non-thread safe state. For example, SimpleDateFormat is infamously not thread-safe, and so the following code is not safe to use in a multi-threaded context: private final static DateFormat df = new SimpleDateFormat ( \"yyyyMMdd\" ); // UNSAFE EXAMPLE private static final Logger < PresentationFieldBuilder > logger = LoggerFactory . getLogger () . withFields ( fb -> fb . string ( \"unsafe_date\" , df . format ( new Date ())));","title":"Thread Safety"},{"location":"usage/fieldbuilder/","text":"Field Builders \u00b6 To do most useful things in Echopraxia, you'll want to define field builders. This page explains the overall API of fields and values, what a field builder does, and how to use it. Imports \u00b6 Start by importing the API package. Everything relevant to field building will be in there. import com.tersesystems.echopraxia.api.* ; Fields and Values \u00b6 Structured logging in Echopraxia is defined using Field and Value . A Field consists of a name() that is a String , and a value() of type Value<?> . Values \u00b6 A Value corresponds mostly to the JSON infoset. It can be a primitive : a string, a number, a boolean, a null, or java.lang.Throwable . Or, it can be complex : an array that contains a list of values, or an object which contains a list of fields. To create a primitive value, you call a static factory method: Value.string(\"string value\") creates a Value<String> Value.nullValue() create a Value<Void> Value.number(intValue) create a Value<Number> Value.bool(true) creates a Value<Boolean> Value.exception(throwable) creates a Value<Throwable> For complex objects, there are some utility methods: Value.array(valueList) takes Value or the known primitives Value.array(function, valueList) will map the elements of valueList into Value using function . Value.object(fields) takes a list of fields Value.object(function, objectList) will map the elements of objectList into Field using function . In addition, there is Value.optional which takes Optional<Value<V>> and returns Value<?> where nullValue is used if Optional.empty() is found. Fields \u00b6 The Field interface has some static methods that are the primary way to create fields: Field.keyValue(name, value) returns a Field with the given name and value set, displaying as \"name=value\" in text. Field.keyValue(name, value, PresentationField.class) returns a PresentationField that has more methods on it. You can also define and extend Field with your own implementation, although that is outside the scope of this section. You can also create a field using Field.value(name, value) or Field.value(name, value, PresentationField.class) , which creates a Field with the presentation attribute asValueOnly set. Field Presentation \u00b6 There are times when the default field presentation is awkward, and you'd like to cut down on the amount of information displayed in the message. You can do this by adding presentation hints to the field. The PresentationField interface implements the Field interface and also provides some extra methods for customizing the presentation of the fields in a line oriented text format. These presentation hints are provided by field attributes and are used by the toString formatter. For the examples, we'll assume that PresentationFieldBuilder is being used here and therefore keyValue returns PresentationField . asValueOnly \u00b6 The asValueOnly method has the effect of turning a \"key=value\" field into a \"value\" field in text format, just like the value method: // same as Field valueField = value(name, value); Field valueField = keyValue ( \"onlyValue\" , Value . string ( \"someText\" )). asValueOnly (); valueField . toString () // renders someText asCardinal \u00b6 The asCardinal method, when used on a field with an array value or on a string, displays the number of elements in the array bracketed by \"|\" characters in text format: var cardinalField = keyValue ( \"elements\" , Value . array ( 1 , 2 , 3 ). asCardinal (); cardinalField . toString (); // renders elements=|3| withDisplayName \u00b6 The withDisplayName method shows a human readable string in text format bracketed in quotes: var readableField = keyValue ( \"json_field\" , Value . number ( 1 )). withDisplayName ( \"human readable name\" ); readableField . toString () // renders \"human readable name\"=1 abbreviateAfter \u00b6 The abbreviateAfter method will truncate an array or string that is very long and replace the rest with ellipsis: var abbrField = keyValue ( \"abbreviatedField\" , Value . string ( veryLongString )). abbreviateAfter ( 5 ); abbrField . toString () // renders abbreviatedField=12345... asElided \u00b6 The asElided method will elide the field so that it is passed over and does not show in text format: var abbrField = keyValue ( \"abbreviatedField\" , Value . string ( veryLongString )). asElided (); abbrField . toString () // renders \"\" This is particularly useful in objects that have elided children that you don't need to see in the message: Field first = keyValue ( \"first\" , string ( \"bar\" )). asElided (); Field second = keyValue ( \"second\" , string ( \"bar\" )); Field third = keyValue ( \"third\" , string ( \"bar\" )). asElided (); List < Field > fields = List . of ( first , second , third ); Field object = keyValue ( \"object\" , Value . object ( fields )); assertThat ( object . toString ()). isEqualTo ( \"object={second=bar}\" ); Defining Field Builders \u00b6 The FieldBuilder interface provides some convenience methods around Field and Value . keyValue : renders a field with name=value when rendered in logfmt line oriented text. value : renders a field with value when rendered in logfmt line oriented text. FieldBuilder comes with some additional methods for common types, i.e. fb.string : creates a field with a string as a value, same as fb.keyValue(name, Value.string(str)) . fb.number : creates a field with a number as a value, same as fb.keyValue(name, Value.number(num)) . fb.bool : creates a field with a boolean as a value, same as fb.keyValue(name, Value.bool(b)) . fb.nullValue : creates a field with a null as a value, same as fb.keyValue(name, Value.nullValue()) fb.array : creates a field with an array as a value, same as fb.keyValue(name, Value.array(arr)) fb.obj : creates a field with an object as a value, same as fb.keyValue(name, Value.``object``(o)) fb.exception : creates a field with a throwable as a value, same as fb.keyValue(name, Value.exception(t)) . The PresentationFieldBuilder interface is the same as FieldBuilder but returns PresentationField by default. To create a field builder, you start with an interface (typically using FieldBuilder or PresentationFieldBuilder as a base) and then pass that field builder into your Logger using withFieldBuilder . Although convenient, you are not required to extend FieldBuilder or PresentationFieldBuilder , and can use Field and Value methods directly to create your own builders (useful if you don't want to expose field names directly). You can then create custom methods on your field builder that will render your class. In this case, we'll create a field builder that can handle a java.util.Date , and create date and dateValue methods for it. import com.tersesystems.echopraxia.api.* ; import java.util.Date ; public interface BuilderWithDate implements PresentationFieldBuilder { static BuilderWithDate instance = new BuilderWithDate () {}; default PresentationField date ( Date date ) { return value ( \"date\" , dateValue ( date )); // use a default name } default PresentationField date ( String name , Date date ) { return value ( name , dateValue ( date )); } // Renders a date as an ISO 8601 string. default Value . StringValue dateValue ( Date date ) { return Value . string ( DateTimeFormatter . ISO_INSTANT . format ( date . toInstant ())); } } And then create a Logger<BuilderWithDate> : Logger<BuilderWithDate> dateLogger = basicLogger.withFieldBuilder(BuilderWithDate.instance); And now you can render a date automatically: dateLogger . info ( \"Date {}\" , fb -> fb . date ( \"creation_date\" , new Date ())); Field Names \u00b6 Allowing the end user to define field names directly can be nice, but also introduces additional complexity. The advantage to using a field name is that it allows a user to distinguish ad-hoc inputs. For example, if you have a start date and an end date: logger.info(\"{} to {}\", fb.list( fb.date(\"start_date\", startDate), fb.date(\"end_date\", endDate) )); This is more convenient than explicitly setting up the field builder with two extra methods and then having to call them: interface BuilderWithDate { default startDate ( Date date ) { return date ( \"start_date\" , date ); } default endDate ( Date date ) { return date ( \"end_date\" , date ); } } logger . info ( \"{} to {}\" , fb . list ( fb . startDate ( startDate ), fb . endDate ( endDate ) )); However, there are downsides to defining names directly in statements, especially when using centralized logging. The first issue is that you may have to sanitize or validate the input name depending on your centralized logging. For example, ElasticSearch does not support field names containing a . (dot) character , so if you do not convert or reject invalid field names. A broader issue is that field names are not scoped by the logger name. Centralized logging does not know that in the FooLogger a field name may be a string, but in the BarLogger , the same field name will be a number. This can cause issues in centralized logging -- ElasticSearch will attempt to define a schema based on dynamic mapping, meaning that if two log statements in the same index have the same field name but different types, i.e. \"error\": 404 vs \"error\": \"not found\" then Elasticsearch will render mapper_parsing_exception and may reject log statements if you do not have ignore_malformed turned on. Even if you turn ignore_malformed on or have different mappings, a change in a mapping across indexes will be enough to stop ElasticSearch from querying correctly. ElasticSearch will also flatten field names, which can cause more confusion as conflicts will only come when objects have both the same field name and property, i.e. they are both called error and are objects that work fine, but fail when an optional code property is added. Likewise, field names are not automatically scoped by context. You may have collision cases where two different fields have the same name in the same statement: logger . withFields ( fb -> fb . keyValue ( \"user_id\" , userId )). info ( \"{}\" , fb -> fb . keyValue ( \"user_id\" , otherUserId )); This will produce a statement that has two user_id fields with two different values -- which is technically valid JSON, but may not be what centralized logging expects. You can qualify your arguments by adding a nested , or add logic that will validate/reject/clean invalid fields, but it may be simpler to explicitly pass in distinct names or namespace with fb.object or Value.object . Managing Null Values \u00b6 At some point you will have a value that you want to render and the Java API will return null . I recommend using Jetbrains annotations which includes a @NotNull annotation. You can defensively program against this by explicitly checking against nulls in the field builder, by explicitly checking against null . import java.time.Duration ; import org.jetbrains.annotations.NotNull ; public interface NullableFieldBuilder extends FieldBuilder { default Value <?> durationValue ( @NotNull Duration duration ) { return ( deadline != null ) ? Value . string ( duration . toString ()) : Value . nullValue (); } } Field names are never allowed to be null. If a field name is null, it will be replaced at runtime with unknown-echopraxia-N where N is an incrementing number. logger . info ( \"Message name {}\" , fb -> fb . string ( null , \"some-value\" ) // null field names not allowed ); Complex Objects \u00b6 The value of a field builder compounds as you build up complex objects from simple ones. In the custom field builder example , the Person class is rendered using a custom field builder: public interface PersonFieldBuilder extends FieldBuilder { // Renders a `Person` as an object field. default Field person ( String fieldName , Person p ) { return keyValue ( fieldName , personValue ( p )); } default Value <?> personValue ( Person p ) { if ( p == null ) return Value . nullValue (); // Note that properties must be broken down to the basic JSON types, // i.e. a primitive string/number/boolean/null or object/array. Field name = string ( \"name\" , p . name ()); Field age = number ( \"age\" , p . age ()); Field father = keyValue ( \"father\" , personValue ( p . getFather ())); Field mother = keyValue ( \"mother\" , personValue ( p . getMother ())); Field interests = array ( \"interests\" , p . interests ()); return Value . object ( name , age , father , mother , interests ); } default Value <?> personValue ( Optional < Person > p ) { return Value . optional ( p . map ( this :: personValue )); } } And then you can render a person: Person user = ... Logger < PersonFieldBuilder > personLogger = basicLogger . withFieldBuilder ( PersonFieldBuilder . instance ); personLogger . info ( \"Person {}\" , fb -> fb . person ( \"user\" , user )); Packages and Modules \u00b6 As you scale up structured logging, you'll eventually reach a point where you'll have mappings for classes that are used in different packages and in different modules. The best practice here is to create a field builder per package, and extend field builder logic by extending interfaces, and use a domain specific Logging interface to manage set up for the end users. For example, you may have a domain driven design that defines classes entities and value objects in a domain layer, and these classes are then specialized and added to in subsequent modules. Say you have a classic e-commerce application. You might have several different modules: A user module containing customer information with address, payment, and authentication details. An order module containing order's components like line items, promotions, and checkout logic, depends on user You would naturally have domain classes organized by package in each module, i.e. the user module would have com.mystore.user.User , and an order would be com.mystore.order.Order and would have a User attached to it. So, define a field builder per package, and add a Logging abstract class that exposes a logger with the appropriate field builder: package com.mystore.user ; // field builder for the user package: interface UserFieldBuilder extends PresentationFieldBuilder { UserFieldBuilder instance = new UserFieldBuilder () {}; default PresentationField user ( User user ) { // ... } } public abstract class LoggingBase { protected static final Logger < UserFieldBuilder > logger = LoggerFactory . getLogger ( this . getClass (), UserFieldBuilder . instance ); } public class SomeUserService extends LoggingBase { public void someMethod ( User user ) { logger . trace ( \"someMethod: {}\" , fb -> fb . user ( user )); } } Because the order package depends on the user package, and an Order contains a User , you want to extend OrderFieldBuilder with UserFieldBuilder package com.mystore.order ; // field builder for the order package interface OrderFieldBuilder extends UserFieldBuilder { OrderFieldBuilder instance = new OrderFieldBuilder () {}; default PresentationField orderId ( OrderId id ) { return ( id == null ) ? nullValue ( \"order_id\" ) : keyValue ( \"order_id\" , id ); } default PresentationField order ( Order order ) { if ( order == null ) return nullField ( \"order\" ); else return object ( \"order\" , orderId ( order . id ), user ( order . user ) /* ...more fields */ ); } } public abstract class LoggingBase { protected static Logger < OrderFieldBuilder > logger = LoggerFactory . getLogger ( this . getClass (), OrderFieldBuilder . instance ); } public class SomeOrderService extends LoggingBase { public void someMethod ( Order order ) { logger . trace ( \"someMethod: {}\" , fb -> fb . order ( order )); } } This way, you can have your loggers automatically \"know\" their domain classes and build on each other without exposing the underlying machinery to end users. Exception Handling \u00b6 Avoid throwing exceptions in a field builder function. Because a field builder function runs in a closure, if an exception is thrown it will be caught by Echopraxia's error handler which writes the exception to System.err by default. logger . info ( \"Message name {}\" , fb -> { String name = methodThatThrowsException (); // BAD return fb . string ( name , \"some-value\" ); }); Instead, only call field builder methods inside the closure and keep any construction logic outside: String name = methodThatThrowsException (); // GOOD logger . info ( \"Message name {}\" , fb -> { return fb . string ( name , \"some-value\" ); }); StructuredFormat \u00b6 Using the withStructuredFormat method with a field visitor will allow the JSON output to contain different fields when you want to provide extra type information that isn't relevant in text. This can be used to show \"human friendly\" fields in a text based format, while showing more machine-readable output in JSON. For example, you may want to render a duration in days: Field durationField = fb . duration ( \"duration\" , Duration . ofDays ( 1 )); assertThat ( durationField . toString ()). isEqualTo ( \"1 day\" ); assertThatJson ( durationField ). inPath ( \"$.duration\" ). asString (). isEqualTo ( \"PT24H\" ); To do this, you would add a field as follows: public class MyFieldBuilder extends PresentationFieldBuilder { public PresentationField duration ( String name , Duration duration ) { Field structuredField = string ( name , duration . toString ()); return string ( name , duration . toDays () + \" day\" ) . asValueOnly () . withStructuredFormat ( new SimpleFieldVisitor () { @Override public @NotNull Field visitString ( @NotNull Value < String > stringValue ) { return structuredField ; } }); } } This is especially relevant for numeric fields where you may want to indicate units -- for example, a retry may indicate a numeric value of seconds, and a cache size may indicate bytes, kilobytes, or gigabytes. Unless you have a pre-defined schema or a consistent naming convention i.e. adding _second suffixes, the unit information is lost and comparing numbers with different units is needlessly complicated. Type information is also useful in string contexts. For example, imagine you want to render a java.lang.Instant in JSON as having an explicit @type of http://www.w3.org/2001/XMLSchema#dateTime alongside the value, but don't want to needlessly complicate your output. Using withStructuredFormat with a class extending SimpleFieldVisitor , you can intercept and override field processing in JSON: public class InstantFieldBuilder implements PresentationFieldBuilder { private static final FieldVisitor instantVisitor = new InstantFieldVisitor (); public PresentationField instant ( String name , Instant instant ) { return string ( name , instant . toString ()). withStructuredFormat ( instantVisitor ); } class InstantFieldVisitor extends SimpleFieldVisitor { @Override public @NotNull Field visitString ( @NotNull Value < String > stringValue ) { return typedInstant ( name , stringValue ); } PresentationField typedInstant ( String name , Value < String > v ) { return object ( name , typedInstantValue ( v )); } Value . ObjectValue typedInstantValue ( Value < String > v ) { return Value . object ( string ( \"@type\" , \"http://www.w3.org/2001/XMLSchema#dateTime\" ), keyValue ( \"@value\" , v )); } @Override public @NotNull ArrayVisitor visitArray () { return new InstantArrayVisitor (); } class InstantArrayVisitor extends SimpleArrayVisitor { @Override public void visitStringElement ( Value . StringValue stringValue ) { this . elements . add ( typedInstantValue ( stringValue )); } } } } This field builder will render fb.instant(\"startTime\", Instant.ofEpochMillis(0)) as the following in text: startTime=1970-01-01T00:00:00Z But will render JSON as: { \"startTime\" : { \"@type\" : \"http://www.w3.org/2001/XMLSchema#dateTime\" , \"@value\" : \"1970-01-01T00:00:00Z\" } } This also applies to Java durations using ISO-8601 which you could mark with a \"@type\": \"https://schema.org/Duration\" and so on.","title":"Field Builders"},{"location":"usage/fieldbuilder/#field-builders","text":"To do most useful things in Echopraxia, you'll want to define field builders. This page explains the overall API of fields and values, what a field builder does, and how to use it.","title":"Field Builders"},{"location":"usage/fieldbuilder/#imports","text":"Start by importing the API package. Everything relevant to field building will be in there. import com.tersesystems.echopraxia.api.* ;","title":"Imports"},{"location":"usage/fieldbuilder/#fields-and-values","text":"Structured logging in Echopraxia is defined using Field and Value . A Field consists of a name() that is a String , and a value() of type Value<?> .","title":"Fields and Values"},{"location":"usage/fieldbuilder/#values","text":"A Value corresponds mostly to the JSON infoset. It can be a primitive : a string, a number, a boolean, a null, or java.lang.Throwable . Or, it can be complex : an array that contains a list of values, or an object which contains a list of fields. To create a primitive value, you call a static factory method: Value.string(\"string value\") creates a Value<String> Value.nullValue() create a Value<Void> Value.number(intValue) create a Value<Number> Value.bool(true) creates a Value<Boolean> Value.exception(throwable) creates a Value<Throwable> For complex objects, there are some utility methods: Value.array(valueList) takes Value or the known primitives Value.array(function, valueList) will map the elements of valueList into Value using function . Value.object(fields) takes a list of fields Value.object(function, objectList) will map the elements of objectList into Field using function . In addition, there is Value.optional which takes Optional<Value<V>> and returns Value<?> where nullValue is used if Optional.empty() is found.","title":"Values"},{"location":"usage/fieldbuilder/#fields","text":"The Field interface has some static methods that are the primary way to create fields: Field.keyValue(name, value) returns a Field with the given name and value set, displaying as \"name=value\" in text. Field.keyValue(name, value, PresentationField.class) returns a PresentationField that has more methods on it. You can also define and extend Field with your own implementation, although that is outside the scope of this section. You can also create a field using Field.value(name, value) or Field.value(name, value, PresentationField.class) , which creates a Field with the presentation attribute asValueOnly set.","title":"Fields"},{"location":"usage/fieldbuilder/#field-presentation","text":"There are times when the default field presentation is awkward, and you'd like to cut down on the amount of information displayed in the message. You can do this by adding presentation hints to the field. The PresentationField interface implements the Field interface and also provides some extra methods for customizing the presentation of the fields in a line oriented text format. These presentation hints are provided by field attributes and are used by the toString formatter. For the examples, we'll assume that PresentationFieldBuilder is being used here and therefore keyValue returns PresentationField .","title":"Field Presentation"},{"location":"usage/fieldbuilder/#asvalueonly","text":"The asValueOnly method has the effect of turning a \"key=value\" field into a \"value\" field in text format, just like the value method: // same as Field valueField = value(name, value); Field valueField = keyValue ( \"onlyValue\" , Value . string ( \"someText\" )). asValueOnly (); valueField . toString () // renders someText","title":"asValueOnly"},{"location":"usage/fieldbuilder/#ascardinal","text":"The asCardinal method, when used on a field with an array value or on a string, displays the number of elements in the array bracketed by \"|\" characters in text format: var cardinalField = keyValue ( \"elements\" , Value . array ( 1 , 2 , 3 ). asCardinal (); cardinalField . toString (); // renders elements=|3|","title":"asCardinal"},{"location":"usage/fieldbuilder/#withdisplayname","text":"The withDisplayName method shows a human readable string in text format bracketed in quotes: var readableField = keyValue ( \"json_field\" , Value . number ( 1 )). withDisplayName ( \"human readable name\" ); readableField . toString () // renders \"human readable name\"=1","title":"withDisplayName"},{"location":"usage/fieldbuilder/#abbreviateafter","text":"The abbreviateAfter method will truncate an array or string that is very long and replace the rest with ellipsis: var abbrField = keyValue ( \"abbreviatedField\" , Value . string ( veryLongString )). abbreviateAfter ( 5 ); abbrField . toString () // renders abbreviatedField=12345...","title":"abbreviateAfter"},{"location":"usage/fieldbuilder/#aselided","text":"The asElided method will elide the field so that it is passed over and does not show in text format: var abbrField = keyValue ( \"abbreviatedField\" , Value . string ( veryLongString )). asElided (); abbrField . toString () // renders \"\" This is particularly useful in objects that have elided children that you don't need to see in the message: Field first = keyValue ( \"first\" , string ( \"bar\" )). asElided (); Field second = keyValue ( \"second\" , string ( \"bar\" )); Field third = keyValue ( \"third\" , string ( \"bar\" )). asElided (); List < Field > fields = List . of ( first , second , third ); Field object = keyValue ( \"object\" , Value . object ( fields )); assertThat ( object . toString ()). isEqualTo ( \"object={second=bar}\" );","title":"asElided"},{"location":"usage/fieldbuilder/#defining-field-builders","text":"The FieldBuilder interface provides some convenience methods around Field and Value . keyValue : renders a field with name=value when rendered in logfmt line oriented text. value : renders a field with value when rendered in logfmt line oriented text. FieldBuilder comes with some additional methods for common types, i.e. fb.string : creates a field with a string as a value, same as fb.keyValue(name, Value.string(str)) . fb.number : creates a field with a number as a value, same as fb.keyValue(name, Value.number(num)) . fb.bool : creates a field with a boolean as a value, same as fb.keyValue(name, Value.bool(b)) . fb.nullValue : creates a field with a null as a value, same as fb.keyValue(name, Value.nullValue()) fb.array : creates a field with an array as a value, same as fb.keyValue(name, Value.array(arr)) fb.obj : creates a field with an object as a value, same as fb.keyValue(name, Value.``object``(o)) fb.exception : creates a field with a throwable as a value, same as fb.keyValue(name, Value.exception(t)) . The PresentationFieldBuilder interface is the same as FieldBuilder but returns PresentationField by default. To create a field builder, you start with an interface (typically using FieldBuilder or PresentationFieldBuilder as a base) and then pass that field builder into your Logger using withFieldBuilder . Although convenient, you are not required to extend FieldBuilder or PresentationFieldBuilder , and can use Field and Value methods directly to create your own builders (useful if you don't want to expose field names directly). You can then create custom methods on your field builder that will render your class. In this case, we'll create a field builder that can handle a java.util.Date , and create date and dateValue methods for it. import com.tersesystems.echopraxia.api.* ; import java.util.Date ; public interface BuilderWithDate implements PresentationFieldBuilder { static BuilderWithDate instance = new BuilderWithDate () {}; default PresentationField date ( Date date ) { return value ( \"date\" , dateValue ( date )); // use a default name } default PresentationField date ( String name , Date date ) { return value ( name , dateValue ( date )); } // Renders a date as an ISO 8601 string. default Value . StringValue dateValue ( Date date ) { return Value . string ( DateTimeFormatter . ISO_INSTANT . format ( date . toInstant ())); } } And then create a Logger<BuilderWithDate> : Logger<BuilderWithDate> dateLogger = basicLogger.withFieldBuilder(BuilderWithDate.instance); And now you can render a date automatically: dateLogger . info ( \"Date {}\" , fb -> fb . date ( \"creation_date\" , new Date ()));","title":"Defining Field Builders"},{"location":"usage/fieldbuilder/#field-names","text":"Allowing the end user to define field names directly can be nice, but also introduces additional complexity. The advantage to using a field name is that it allows a user to distinguish ad-hoc inputs. For example, if you have a start date and an end date: logger.info(\"{} to {}\", fb.list( fb.date(\"start_date\", startDate), fb.date(\"end_date\", endDate) )); This is more convenient than explicitly setting up the field builder with two extra methods and then having to call them: interface BuilderWithDate { default startDate ( Date date ) { return date ( \"start_date\" , date ); } default endDate ( Date date ) { return date ( \"end_date\" , date ); } } logger . info ( \"{} to {}\" , fb . list ( fb . startDate ( startDate ), fb . endDate ( endDate ) )); However, there are downsides to defining names directly in statements, especially when using centralized logging. The first issue is that you may have to sanitize or validate the input name depending on your centralized logging. For example, ElasticSearch does not support field names containing a . (dot) character , so if you do not convert or reject invalid field names. A broader issue is that field names are not scoped by the logger name. Centralized logging does not know that in the FooLogger a field name may be a string, but in the BarLogger , the same field name will be a number. This can cause issues in centralized logging -- ElasticSearch will attempt to define a schema based on dynamic mapping, meaning that if two log statements in the same index have the same field name but different types, i.e. \"error\": 404 vs \"error\": \"not found\" then Elasticsearch will render mapper_parsing_exception and may reject log statements if you do not have ignore_malformed turned on. Even if you turn ignore_malformed on or have different mappings, a change in a mapping across indexes will be enough to stop ElasticSearch from querying correctly. ElasticSearch will also flatten field names, which can cause more confusion as conflicts will only come when objects have both the same field name and property, i.e. they are both called error and are objects that work fine, but fail when an optional code property is added. Likewise, field names are not automatically scoped by context. You may have collision cases where two different fields have the same name in the same statement: logger . withFields ( fb -> fb . keyValue ( \"user_id\" , userId )). info ( \"{}\" , fb -> fb . keyValue ( \"user_id\" , otherUserId )); This will produce a statement that has two user_id fields with two different values -- which is technically valid JSON, but may not be what centralized logging expects. You can qualify your arguments by adding a nested , or add logic that will validate/reject/clean invalid fields, but it may be simpler to explicitly pass in distinct names or namespace with fb.object or Value.object .","title":"Field Names"},{"location":"usage/fieldbuilder/#managing-null-values","text":"At some point you will have a value that you want to render and the Java API will return null . I recommend using Jetbrains annotations which includes a @NotNull annotation. You can defensively program against this by explicitly checking against nulls in the field builder, by explicitly checking against null . import java.time.Duration ; import org.jetbrains.annotations.NotNull ; public interface NullableFieldBuilder extends FieldBuilder { default Value <?> durationValue ( @NotNull Duration duration ) { return ( deadline != null ) ? Value . string ( duration . toString ()) : Value . nullValue (); } } Field names are never allowed to be null. If a field name is null, it will be replaced at runtime with unknown-echopraxia-N where N is an incrementing number. logger . info ( \"Message name {}\" , fb -> fb . string ( null , \"some-value\" ) // null field names not allowed );","title":"Managing Null Values"},{"location":"usage/fieldbuilder/#complex-objects","text":"The value of a field builder compounds as you build up complex objects from simple ones. In the custom field builder example , the Person class is rendered using a custom field builder: public interface PersonFieldBuilder extends FieldBuilder { // Renders a `Person` as an object field. default Field person ( String fieldName , Person p ) { return keyValue ( fieldName , personValue ( p )); } default Value <?> personValue ( Person p ) { if ( p == null ) return Value . nullValue (); // Note that properties must be broken down to the basic JSON types, // i.e. a primitive string/number/boolean/null or object/array. Field name = string ( \"name\" , p . name ()); Field age = number ( \"age\" , p . age ()); Field father = keyValue ( \"father\" , personValue ( p . getFather ())); Field mother = keyValue ( \"mother\" , personValue ( p . getMother ())); Field interests = array ( \"interests\" , p . interests ()); return Value . object ( name , age , father , mother , interests ); } default Value <?> personValue ( Optional < Person > p ) { return Value . optional ( p . map ( this :: personValue )); } } And then you can render a person: Person user = ... Logger < PersonFieldBuilder > personLogger = basicLogger . withFieldBuilder ( PersonFieldBuilder . instance ); personLogger . info ( \"Person {}\" , fb -> fb . person ( \"user\" , user ));","title":"Complex Objects"},{"location":"usage/fieldbuilder/#packages-and-modules","text":"As you scale up structured logging, you'll eventually reach a point where you'll have mappings for classes that are used in different packages and in different modules. The best practice here is to create a field builder per package, and extend field builder logic by extending interfaces, and use a domain specific Logging interface to manage set up for the end users. For example, you may have a domain driven design that defines classes entities and value objects in a domain layer, and these classes are then specialized and added to in subsequent modules. Say you have a classic e-commerce application. You might have several different modules: A user module containing customer information with address, payment, and authentication details. An order module containing order's components like line items, promotions, and checkout logic, depends on user You would naturally have domain classes organized by package in each module, i.e. the user module would have com.mystore.user.User , and an order would be com.mystore.order.Order and would have a User attached to it. So, define a field builder per package, and add a Logging abstract class that exposes a logger with the appropriate field builder: package com.mystore.user ; // field builder for the user package: interface UserFieldBuilder extends PresentationFieldBuilder { UserFieldBuilder instance = new UserFieldBuilder () {}; default PresentationField user ( User user ) { // ... } } public abstract class LoggingBase { protected static final Logger < UserFieldBuilder > logger = LoggerFactory . getLogger ( this . getClass (), UserFieldBuilder . instance ); } public class SomeUserService extends LoggingBase { public void someMethod ( User user ) { logger . trace ( \"someMethod: {}\" , fb -> fb . user ( user )); } } Because the order package depends on the user package, and an Order contains a User , you want to extend OrderFieldBuilder with UserFieldBuilder package com.mystore.order ; // field builder for the order package interface OrderFieldBuilder extends UserFieldBuilder { OrderFieldBuilder instance = new OrderFieldBuilder () {}; default PresentationField orderId ( OrderId id ) { return ( id == null ) ? nullValue ( \"order_id\" ) : keyValue ( \"order_id\" , id ); } default PresentationField order ( Order order ) { if ( order == null ) return nullField ( \"order\" ); else return object ( \"order\" , orderId ( order . id ), user ( order . user ) /* ...more fields */ ); } } public abstract class LoggingBase { protected static Logger < OrderFieldBuilder > logger = LoggerFactory . getLogger ( this . getClass (), OrderFieldBuilder . instance ); } public class SomeOrderService extends LoggingBase { public void someMethod ( Order order ) { logger . trace ( \"someMethod: {}\" , fb -> fb . order ( order )); } } This way, you can have your loggers automatically \"know\" their domain classes and build on each other without exposing the underlying machinery to end users.","title":"Packages and Modules"},{"location":"usage/fieldbuilder/#exception-handling","text":"Avoid throwing exceptions in a field builder function. Because a field builder function runs in a closure, if an exception is thrown it will be caught by Echopraxia's error handler which writes the exception to System.err by default. logger . info ( \"Message name {}\" , fb -> { String name = methodThatThrowsException (); // BAD return fb . string ( name , \"some-value\" ); }); Instead, only call field builder methods inside the closure and keep any construction logic outside: String name = methodThatThrowsException (); // GOOD logger . info ( \"Message name {}\" , fb -> { return fb . string ( name , \"some-value\" ); });","title":"Exception Handling"},{"location":"usage/fieldbuilder/#structuredformat","text":"Using the withStructuredFormat method with a field visitor will allow the JSON output to contain different fields when you want to provide extra type information that isn't relevant in text. This can be used to show \"human friendly\" fields in a text based format, while showing more machine-readable output in JSON. For example, you may want to render a duration in days: Field durationField = fb . duration ( \"duration\" , Duration . ofDays ( 1 )); assertThat ( durationField . toString ()). isEqualTo ( \"1 day\" ); assertThatJson ( durationField ). inPath ( \"$.duration\" ). asString (). isEqualTo ( \"PT24H\" ); To do this, you would add a field as follows: public class MyFieldBuilder extends PresentationFieldBuilder { public PresentationField duration ( String name , Duration duration ) { Field structuredField = string ( name , duration . toString ()); return string ( name , duration . toDays () + \" day\" ) . asValueOnly () . withStructuredFormat ( new SimpleFieldVisitor () { @Override public @NotNull Field visitString ( @NotNull Value < String > stringValue ) { return structuredField ; } }); } } This is especially relevant for numeric fields where you may want to indicate units -- for example, a retry may indicate a numeric value of seconds, and a cache size may indicate bytes, kilobytes, or gigabytes. Unless you have a pre-defined schema or a consistent naming convention i.e. adding _second suffixes, the unit information is lost and comparing numbers with different units is needlessly complicated. Type information is also useful in string contexts. For example, imagine you want to render a java.lang.Instant in JSON as having an explicit @type of http://www.w3.org/2001/XMLSchema#dateTime alongside the value, but don't want to needlessly complicate your output. Using withStructuredFormat with a class extending SimpleFieldVisitor , you can intercept and override field processing in JSON: public class InstantFieldBuilder implements PresentationFieldBuilder { private static final FieldVisitor instantVisitor = new InstantFieldVisitor (); public PresentationField instant ( String name , Instant instant ) { return string ( name , instant . toString ()). withStructuredFormat ( instantVisitor ); } class InstantFieldVisitor extends SimpleFieldVisitor { @Override public @NotNull Field visitString ( @NotNull Value < String > stringValue ) { return typedInstant ( name , stringValue ); } PresentationField typedInstant ( String name , Value < String > v ) { return object ( name , typedInstantValue ( v )); } Value . ObjectValue typedInstantValue ( Value < String > v ) { return Value . object ( string ( \"@type\" , \"http://www.w3.org/2001/XMLSchema#dateTime\" ), keyValue ( \"@value\" , v )); } @Override public @NotNull ArrayVisitor visitArray () { return new InstantArrayVisitor (); } class InstantArrayVisitor extends SimpleArrayVisitor { @Override public void visitStringElement ( Value . StringValue stringValue ) { this . elements . add ( typedInstantValue ( stringValue )); } } } } This field builder will render fb.instant(\"startTime\", Instant.ofEpochMillis(0)) as the following in text: startTime=1970-01-01T00:00:00Z But will render JSON as: { \"startTime\" : { \"@type\" : \"http://www.w3.org/2001/XMLSchema#dateTime\" , \"@value\" : \"1970-01-01T00:00:00Z\" } } This also applies to Java durations using ISO-8601 which you could mark with a \"@type\": \"https://schema.org/Duration\" and so on.","title":"StructuredFormat"},{"location":"usage/filters/","text":"Filters \u00b6 There are times when you want to add a field or a condition to all loggers. Although you can wrap individual loggers or create your own wrapper around LoggerFactory , this can be a labor-intensive process that requires lots of code modification, and must be handled for fluent, semantic, async, and regular loggers. Echopraxia includes filters that wrap around the CoreLogger returned by CoreLoggerFactory that provides the ability to modify the core logger from a single pipeline in the code. For example, to add a uses_filter field to every Echopraxia logger: package example ; import com.tersesystems.echopraxia.api.* ; public class ExampleFilter implements CoreLoggerFilter { @Override public CoreLogger apply ( CoreLogger coreLogger ) { return coreLogger . withFields ( fb -> fb . bool ( \"uses_filter\" , true ), FieldBuilder . instance ()); } } Filters must extend the CoreLoggerFilter interface, and must have a no-args constructor. Filters must have a fully qualified class name in the /echopraxia.properties file as a resource somewhere in your classpath. The format is filter.N where N is the order in which filters should be loaded. filter.0 = example.ExampleFilter Filters are particularly helpful when you need to provide \"out of context\" information for your conditions. For example, imagine that you have a situation in which the program uses more CPU or memory than normal in production, but works fine in a staging environment. Using OSHI and a filter, you can provide the machine statistics and evaluate with dynamic conditions. public class SystemInfoFilter implements CoreLoggerFilter { private final SystemInfo systemInfo ; public SystemInfoFilter () { systemInfo = new SystemInfo (); } @Override public CoreLogger apply ( CoreLogger coreLogger ) { HardwareAbstractionLayer hardware = systemInfo . getHardware (); GlobalMemory mem = hardware . getMemory (); CentralProcessor proc = hardware . getProcessor (); double [] loadAverage = proc . getSystemLoadAverage ( 3 ); // Now you can add conditions based on these fields, and conditionally // enable logging based on your load and memory! return coreLogger . withFields ( fb -> { Field loadField = fb . object ( \"load_average\" , // fb . number ( \"1min\" , loadAverage [ 0 ] ), // fb . number ( \"5min\" , loadAverage [ 1 ] ), // fb . number ( \"15min\" , loadAverage [ 2 ] )); Field memField = fb . object ( \"mem\" , // fb . number ( \"available\" , mem . getAvailable ()), // fb . number ( \"total\" , mem . getTotal ())); Field sysinfoField = fb . object ( \"sysinfo\" , loadField , memField ); return sysinfoField ; }, FieldBuilder . instance ()); } } Please see the system info example for details.","title":"Filters"},{"location":"usage/filters/#filters","text":"There are times when you want to add a field or a condition to all loggers. Although you can wrap individual loggers or create your own wrapper around LoggerFactory , this can be a labor-intensive process that requires lots of code modification, and must be handled for fluent, semantic, async, and regular loggers. Echopraxia includes filters that wrap around the CoreLogger returned by CoreLoggerFactory that provides the ability to modify the core logger from a single pipeline in the code. For example, to add a uses_filter field to every Echopraxia logger: package example ; import com.tersesystems.echopraxia.api.* ; public class ExampleFilter implements CoreLoggerFilter { @Override public CoreLogger apply ( CoreLogger coreLogger ) { return coreLogger . withFields ( fb -> fb . bool ( \"uses_filter\" , true ), FieldBuilder . instance ()); } } Filters must extend the CoreLoggerFilter interface, and must have a no-args constructor. Filters must have a fully qualified class name in the /echopraxia.properties file as a resource somewhere in your classpath. The format is filter.N where N is the order in which filters should be loaded. filter.0 = example.ExampleFilter Filters are particularly helpful when you need to provide \"out of context\" information for your conditions. For example, imagine that you have a situation in which the program uses more CPU or memory than normal in production, but works fine in a staging environment. Using OSHI and a filter, you can provide the machine statistics and evaluate with dynamic conditions. public class SystemInfoFilter implements CoreLoggerFilter { private final SystemInfo systemInfo ; public SystemInfoFilter () { systemInfo = new SystemInfo (); } @Override public CoreLogger apply ( CoreLogger coreLogger ) { HardwareAbstractionLayer hardware = systemInfo . getHardware (); GlobalMemory mem = hardware . getMemory (); CentralProcessor proc = hardware . getProcessor (); double [] loadAverage = proc . getSystemLoadAverage ( 3 ); // Now you can add conditions based on these fields, and conditionally // enable logging based on your load and memory! return coreLogger . withFields ( fb -> { Field loadField = fb . object ( \"load_average\" , // fb . number ( \"1min\" , loadAverage [ 0 ] ), // fb . number ( \"5min\" , loadAverage [ 1 ] ), // fb . number ( \"15min\" , loadAverage [ 2 ] )); Field memField = fb . object ( \"mem\" , // fb . number ( \"available\" , mem . getAvailable ()), // fb . number ( \"total\" , mem . getTotal ())); Field sysinfoField = fb . object ( \"sysinfo\" , loadField , memField ); return sysinfoField ; }, FieldBuilder . instance ()); } } Please see the system info example for details.","title":"Filters"},{"location":"usage/logger/","text":"Custom Logger \u00b6 If you are using a particular set of field builders for your domain and want them available by default, it's easy to create your own logger with your own field builder, using the support classes and interfaces. Creating your own logger will also remove the type parameter from your code, so you don't have to type Logger<PersonFieldBuilder> everywhere, and allow you to create custom methods that leverage field builders. If you want to make sure your logger is the only one available, you should import only the API: Maven: <dependency> <groupId>com.tersesystems.echopraxia</groupId> <artifactId>api</artifactId> <version><VERSION></version> </dependency> Gradle: implementation \"com.tersesystems.echopraxia:api:<VERSION>\" And then continuing on from the custom field builder example , you can build a PersonLogger : import com.tersesystems.echopraxia.api.* ; import com.tersesystems.echopraxia.spi.* ; public final class PersonLogger extends AbstractLoggerSupport < PersonLogger , PersonFieldBuilder > implements DefaultLoggerMethods < PersonFieldBuilder > { private static final String FQCN = PersonLogger . class . getName (); protected PersonLogger ( @NotNull CoreLogger core , @NotNull PersonFieldBuilder fieldBuilder , Class <?> selfType ) { super ( core , fieldBuilder , selfType ); } public void info ( @Nullable String message , Person person ) { // when using custom methods, you must specify the caller as the class it's defined in. this . core (). withFQCN ( FQCN ). log ( Level . INFO , message , fb -> fb . person ( \"person\" , person ), fieldBuilder ); } @Override protected @NotNull PersonLogger newLogger ( CoreLogger core ) { return new PersonLogger ( core , fieldBuilder (), PersonLogger . class ); } @Override protected @NotNull PersonLogger neverLogger () { return new PersonLogger ( core . withCondition ( Condition . never ()), fieldBuilder (), PersonLogger . class ); } } and a custom logger factory: public final class PersonLoggerFactory { private static final PersonFieldBuilder myFieldBuilder = PersonFieldBuilder . instance ; // the class containing the error/warn/info/debug/trace methods private static final String FQCN = DefaultLoggerMethods . class . getName (); public static PersonLogger getLogger ( Class <?> clazz ) { return getLogger ( CoreLoggerFactory . getLogger ( FQCN , clazz . getName ())); } public static PersonLogger getLogger ( String name ) { return getLogger ( CoreLoggerFactory . getLogger ( FQCN , name )); } public static PersonLogger getLogger () { return getLogger ( CoreLoggerFactory . getLogger ( FQCN , Caller . resolveClassName ())); } public static PersonLogger getLogger ( @NotNull CoreLogger core ) { return new PersonLogger ( core , myFieldBuilder , PersonLogger . class ); } } and then you can log a person as a raw parameter: PersonLogger logger = PersonLoggerFactory . getLogger (); Person abe = ... logger . info ( \"Best person: {}\" , abe ); Generally loggers should be final, and any common functionality should be moved out to interfaces you can share. This is because subclassing can have an impact on JVM optimizations, and can make returning specific types from with* methods more complicated.","title":"Custom Logger"},{"location":"usage/logger/#custom-logger","text":"If you are using a particular set of field builders for your domain and want them available by default, it's easy to create your own logger with your own field builder, using the support classes and interfaces. Creating your own logger will also remove the type parameter from your code, so you don't have to type Logger<PersonFieldBuilder> everywhere, and allow you to create custom methods that leverage field builders. If you want to make sure your logger is the only one available, you should import only the API: Maven: <dependency> <groupId>com.tersesystems.echopraxia</groupId> <artifactId>api</artifactId> <version><VERSION></version> </dependency> Gradle: implementation \"com.tersesystems.echopraxia:api:<VERSION>\" And then continuing on from the custom field builder example , you can build a PersonLogger : import com.tersesystems.echopraxia.api.* ; import com.tersesystems.echopraxia.spi.* ; public final class PersonLogger extends AbstractLoggerSupport < PersonLogger , PersonFieldBuilder > implements DefaultLoggerMethods < PersonFieldBuilder > { private static final String FQCN = PersonLogger . class . getName (); protected PersonLogger ( @NotNull CoreLogger core , @NotNull PersonFieldBuilder fieldBuilder , Class <?> selfType ) { super ( core , fieldBuilder , selfType ); } public void info ( @Nullable String message , Person person ) { // when using custom methods, you must specify the caller as the class it's defined in. this . core (). withFQCN ( FQCN ). log ( Level . INFO , message , fb -> fb . person ( \"person\" , person ), fieldBuilder ); } @Override protected @NotNull PersonLogger newLogger ( CoreLogger core ) { return new PersonLogger ( core , fieldBuilder (), PersonLogger . class ); } @Override protected @NotNull PersonLogger neverLogger () { return new PersonLogger ( core . withCondition ( Condition . never ()), fieldBuilder (), PersonLogger . class ); } } and a custom logger factory: public final class PersonLoggerFactory { private static final PersonFieldBuilder myFieldBuilder = PersonFieldBuilder . instance ; // the class containing the error/warn/info/debug/trace methods private static final String FQCN = DefaultLoggerMethods . class . getName (); public static PersonLogger getLogger ( Class <?> clazz ) { return getLogger ( CoreLoggerFactory . getLogger ( FQCN , clazz . getName ())); } public static PersonLogger getLogger ( String name ) { return getLogger ( CoreLoggerFactory . getLogger ( FQCN , name )); } public static PersonLogger getLogger () { return getLogger ( CoreLoggerFactory . getLogger ( FQCN , Caller . resolveClassName ())); } public static PersonLogger getLogger ( @NotNull CoreLogger core ) { return new PersonLogger ( core , myFieldBuilder , PersonLogger . class ); } } and then you can log a person as a raw parameter: PersonLogger logger = PersonLoggerFactory . getLogger (); Person abe = ... logger . info ( \"Best person: {}\" , abe ); Generally loggers should be final, and any common functionality should be moved out to interfaces you can share. This is because subclassing can have an impact on JVM optimizations, and can make returning specific types from with* methods more complicated.","title":"Custom Logger"},{"location":"usage/scripting/","text":"Dynamic Conditions with Scripts \u00b6 One of the limitations of logging is that it's not that easy to change logging levels in an application at run-time. In modern applications, you typically have complex inputs and may want to enable logging for some very specific inputs without turning on your logging globally. Script Conditions lets you tie your conditions to scripts that you can change and re-evaluate at runtime. The security concerns surrounding Groovy or Javascript make them unsuitable in a logging environment. Fortunately, Echopraxia provides a Tweakflow script integration that lets you evaluate logging statements safely . Tweakflow comes with a VS Code integration , a reference guide , and a standard library that contains useful regular expression and date manipulation logic. Installation \u00b6 Because Scripting has a dependency on Tweakflow, it is broken out into a distinct library that you must add to your build. Maven: <dependency> <groupId> com.tersesystems.echopraxia </groupId> <artifactId> scripting </artifactId> <version><VERSION></version> </dependency> Gradle: implementation \"com.tersesystems.echopraxia:scripting:<VERSION>\" Script Syntax \u00b6 The call site for a script is the function evaluate inside a library called echopraxia . The level and context are passed through as (string level, dict ctx) , where ctx is a dictionary of functions that connect back to the logging context. Methods in the context are snake case, separated by underscores. For example, to call the equivalent of ctx.findString(\"$.person.name\") , you would call ctx[:find_string](\"$.person.name\") . ctx[:find_number] returns a number or null ctx[:find_string] returns a string or null ctx[:find_boolean] returns a boolean or null ctx[:find_object] returns a dict or null ctx[:find_list] returns a list or null ctx[:find_null] returns a boolean ctx[:fields] returns a list of fields You can use the let construct in Tweakflow to make this clearer: library echopraxia { function evaluate: (string level, dict ctx) -> let { find_string: ctx[:find_string]; } find_string(\"$.person.name\") == \"testing\"; } Using find_object or find_list returns the appropriate type of dict or list respectively. library echopraxia { function evaluate: (string level, dict ctx) -> let { find_list: ctx[:find_list]; interests: find_list(\"$.obj.interests\"); } interests[1] == \"drink\"; } And you can use the Tweakflow standard library to allow for more advanced functionality, i.e. import * as std from \"std\"; alias std.strings as str; library echopraxia { function evaluate: (string level, dict ctx) -> let { find_string: ctx[:find_string]; } str.lower_case(find_string(\"$.person.name\")) == \"will\"; } The context method also has functionality to access \"impure\" methods such as the current instant, using ctx[:now] : import * as std from \"std\"; alias std.time as time; library echopraxia { function evaluate: (string level, dict ctx) -> let { now: ctx[:now]; } time.unix_timestamp(now()) > 0; } If you want to look at intermediate results, you can use the debug function which will print out values to System.out : library echopraxia { function evaluate: (string level, dict ctx) -> let { now: ctx[:now]; } debug(now()) && true; } Creating Script Conditions \u00b6 The simplest way to handle a script is to pass it in directly as a string: import com.tersesystems.echopraxia.scripting.* ; StringBuilder b = new StringBuilder ( \"\" ); b . append ( \"library echopraxia {\" ); b . append ( \" function evaluate: (string level, dict ctx) ->\" ); b . append ( \" level == \\\"info\\\";\" ); b . append ( \"}\" ); String scriptString = b . toString (); Condition c = ScriptCondition . create ( false , scriptString , Throwable :: printStackTrace ); You can also use a Path for file based scripts: import com.tersesystems.echopraxia.scripting.* ; Path path = Paths . get ( \"src/test/tweakflow/condition.tf\" ); Condition condition = ScriptCondition . create ( false , path , Throwable :: printStackTrace ); var logger = LoggerFactory . getLogger ( getClass ()). withCondition ( condition ); Where condition.tf contains a tweakflow script, e.g. import * as std from \"std\"; alias std.strings as str; library echopraxia { # level: the logging level # ctx: the logging context function evaluate: (string level, dict ctx) -> let { find_string: ctx[:find_string]; } str.lower_case(find_string(\"$.person.name\")) == \"will\"; } You also have the option to store scripts in a key-value store or in a database. See the sqlite condition store example for details. User Defined Functions \u00b6 You have the option of passing in user defined functions into the script, in addition to the built-in scripts. import com.tersesystems.echopraxia.scripting.* ; import com.twineworks.tweakflow.lang.types.Type ; import com.twineworks.tweakflow.lang.types.Types ; import com.twineworks.tweakflow.lang.values.* ; class NowFunction { private UserFunctionValue nowFunction () { return ScriptFunction . builder () . supplier (() -> Values . make ( Instant . now ())) . result ( Types . DATETIME ) . build (); } public final List < ValueMapEntry > userFunctions = Collections . singletonList ( new ValueMapEntry ( \"now\" , Values . make ( nowFunction ()))); public void logWithNow () { Path path = Paths . get ( \"src/test/tweakflow/condition.tf\" ); Condition condition = ScriptCondition . create ( ctx -> userFunctions , false , path , Throwable :: printStackTrace ); var logger = LoggerFactory . getLogger ( getClass ()). withCondition ( condition ); } } This will allow you to access Instant.now() whenever you call the function attached to ctx[:now] : import * as std from \"std\"; alias std.time as time; library echopraxia { function evaluate: (string level, dict ctx) -> let { now: ctx[:now]; } time.unix_timestamp(now()) > 0; } You can access the core logger and the underlying framework logger through the context: Function < LoggingContext , List < ValueMapEntry >> userFunctions = ctx -> { UserFunctionValue f = ScriptFunction . builder () . parameter ( new FunctionParameter ( 0 , \"property_name\" , Types . STRING , Values . make ( \"\" ))) . function ( propertyName -> { LogstashCoreLogger core = ( LogstashCoreLogger ) ctx . getCore (); LoggerContext loggerContext = core . logger (). getLoggerContext (); String propertyValue = loggerContext . getProperty ( propertyName . string ()); return Values . make ( propertyValue ); }) . result ( Types . STRING ) . build ()) return Collections . singletonList ( ValueMapEntry . make ( \"logger_property\" , f ); } With this user defined function, you can set a logback property: <configuration > <property name= \"herp\" value= \"derp\" scope= \"context\" / > </configuration > And then access the property using ctx[:logger_property](\"herp\") . Watched Scripts \u00b6 You can change file based scripts while the application is running, if they are in a directory watched by ScriptWatchService . To configure ScriptWatchService , pass it the directory that contains your script files: final Path watchedDir = Paths . get ( \"/your/script/directory\" ); ScriptWatchService watchService = new ScriptWatchService ( watchedDir ); Path filePath = watchedDir . resolve ( \"myscript.tf\" ); Logger logger = LoggerFactory . getLogger (); final ScriptHandle watchedHandle = watchService . watchScript ( filePath , e -> logger . error ( \"Script compilation error\" , e )); final Condition condition = ScriptCondition . create ( watchedHandle ); logger . info ( condition , \"Statement only logs if condition is met!\" ) // After that, you can edit myscript.tf and the condition will // re-evaluate the script as needed automatically! // You can delete the file, but doing so will log a warning from `ScriptWatchService` // Recreating a deleted file will trigger an evaluation, same as modification. // Note that the watch service creates a daemon thread to watch the directory. // To free up the thread and stop watching, you should call close() as appropriate: watchService . close (); Please see the scripting example for more details.","title":"Scripting"},{"location":"usage/scripting/#dynamic-conditions-with-scripts","text":"One of the limitations of logging is that it's not that easy to change logging levels in an application at run-time. In modern applications, you typically have complex inputs and may want to enable logging for some very specific inputs without turning on your logging globally. Script Conditions lets you tie your conditions to scripts that you can change and re-evaluate at runtime. The security concerns surrounding Groovy or Javascript make them unsuitable in a logging environment. Fortunately, Echopraxia provides a Tweakflow script integration that lets you evaluate logging statements safely . Tweakflow comes with a VS Code integration , a reference guide , and a standard library that contains useful regular expression and date manipulation logic.","title":"Dynamic Conditions with Scripts"},{"location":"usage/scripting/#installation","text":"Because Scripting has a dependency on Tweakflow, it is broken out into a distinct library that you must add to your build. Maven: <dependency> <groupId> com.tersesystems.echopraxia </groupId> <artifactId> scripting </artifactId> <version><VERSION></version> </dependency> Gradle: implementation \"com.tersesystems.echopraxia:scripting:<VERSION>\"","title":"Installation"},{"location":"usage/scripting/#script-syntax","text":"The call site for a script is the function evaluate inside a library called echopraxia . The level and context are passed through as (string level, dict ctx) , where ctx is a dictionary of functions that connect back to the logging context. Methods in the context are snake case, separated by underscores. For example, to call the equivalent of ctx.findString(\"$.person.name\") , you would call ctx[:find_string](\"$.person.name\") . ctx[:find_number] returns a number or null ctx[:find_string] returns a string or null ctx[:find_boolean] returns a boolean or null ctx[:find_object] returns a dict or null ctx[:find_list] returns a list or null ctx[:find_null] returns a boolean ctx[:fields] returns a list of fields You can use the let construct in Tweakflow to make this clearer: library echopraxia { function evaluate: (string level, dict ctx) -> let { find_string: ctx[:find_string]; } find_string(\"$.person.name\") == \"testing\"; } Using find_object or find_list returns the appropriate type of dict or list respectively. library echopraxia { function evaluate: (string level, dict ctx) -> let { find_list: ctx[:find_list]; interests: find_list(\"$.obj.interests\"); } interests[1] == \"drink\"; } And you can use the Tweakflow standard library to allow for more advanced functionality, i.e. import * as std from \"std\"; alias std.strings as str; library echopraxia { function evaluate: (string level, dict ctx) -> let { find_string: ctx[:find_string]; } str.lower_case(find_string(\"$.person.name\")) == \"will\"; } The context method also has functionality to access \"impure\" methods such as the current instant, using ctx[:now] : import * as std from \"std\"; alias std.time as time; library echopraxia { function evaluate: (string level, dict ctx) -> let { now: ctx[:now]; } time.unix_timestamp(now()) > 0; } If you want to look at intermediate results, you can use the debug function which will print out values to System.out : library echopraxia { function evaluate: (string level, dict ctx) -> let { now: ctx[:now]; } debug(now()) && true; }","title":"Script Syntax"},{"location":"usage/scripting/#creating-script-conditions","text":"The simplest way to handle a script is to pass it in directly as a string: import com.tersesystems.echopraxia.scripting.* ; StringBuilder b = new StringBuilder ( \"\" ); b . append ( \"library echopraxia {\" ); b . append ( \" function evaluate: (string level, dict ctx) ->\" ); b . append ( \" level == \\\"info\\\";\" ); b . append ( \"}\" ); String scriptString = b . toString (); Condition c = ScriptCondition . create ( false , scriptString , Throwable :: printStackTrace ); You can also use a Path for file based scripts: import com.tersesystems.echopraxia.scripting.* ; Path path = Paths . get ( \"src/test/tweakflow/condition.tf\" ); Condition condition = ScriptCondition . create ( false , path , Throwable :: printStackTrace ); var logger = LoggerFactory . getLogger ( getClass ()). withCondition ( condition ); Where condition.tf contains a tweakflow script, e.g. import * as std from \"std\"; alias std.strings as str; library echopraxia { # level: the logging level # ctx: the logging context function evaluate: (string level, dict ctx) -> let { find_string: ctx[:find_string]; } str.lower_case(find_string(\"$.person.name\")) == \"will\"; } You also have the option to store scripts in a key-value store or in a database. See the sqlite condition store example for details.","title":"Creating Script Conditions"},{"location":"usage/scripting/#user-defined-functions","text":"You have the option of passing in user defined functions into the script, in addition to the built-in scripts. import com.tersesystems.echopraxia.scripting.* ; import com.twineworks.tweakflow.lang.types.Type ; import com.twineworks.tweakflow.lang.types.Types ; import com.twineworks.tweakflow.lang.values.* ; class NowFunction { private UserFunctionValue nowFunction () { return ScriptFunction . builder () . supplier (() -> Values . make ( Instant . now ())) . result ( Types . DATETIME ) . build (); } public final List < ValueMapEntry > userFunctions = Collections . singletonList ( new ValueMapEntry ( \"now\" , Values . make ( nowFunction ()))); public void logWithNow () { Path path = Paths . get ( \"src/test/tweakflow/condition.tf\" ); Condition condition = ScriptCondition . create ( ctx -> userFunctions , false , path , Throwable :: printStackTrace ); var logger = LoggerFactory . getLogger ( getClass ()). withCondition ( condition ); } } This will allow you to access Instant.now() whenever you call the function attached to ctx[:now] : import * as std from \"std\"; alias std.time as time; library echopraxia { function evaluate: (string level, dict ctx) -> let { now: ctx[:now]; } time.unix_timestamp(now()) > 0; } You can access the core logger and the underlying framework logger through the context: Function < LoggingContext , List < ValueMapEntry >> userFunctions = ctx -> { UserFunctionValue f = ScriptFunction . builder () . parameter ( new FunctionParameter ( 0 , \"property_name\" , Types . STRING , Values . make ( \"\" ))) . function ( propertyName -> { LogstashCoreLogger core = ( LogstashCoreLogger ) ctx . getCore (); LoggerContext loggerContext = core . logger (). getLoggerContext (); String propertyValue = loggerContext . getProperty ( propertyName . string ()); return Values . make ( propertyValue ); }) . result ( Types . STRING ) . build ()) return Collections . singletonList ( ValueMapEntry . make ( \"logger_property\" , f ); } With this user defined function, you can set a logback property: <configuration > <property name= \"herp\" value= \"derp\" scope= \"context\" / > </configuration > And then access the property using ctx[:logger_property](\"herp\") .","title":"User Defined Functions"},{"location":"usage/scripting/#watched-scripts","text":"You can change file based scripts while the application is running, if they are in a directory watched by ScriptWatchService . To configure ScriptWatchService , pass it the directory that contains your script files: final Path watchedDir = Paths . get ( \"/your/script/directory\" ); ScriptWatchService watchService = new ScriptWatchService ( watchedDir ); Path filePath = watchedDir . resolve ( \"myscript.tf\" ); Logger logger = LoggerFactory . getLogger (); final ScriptHandle watchedHandle = watchService . watchScript ( filePath , e -> logger . error ( \"Script compilation error\" , e )); final Condition condition = ScriptCondition . create ( watchedHandle ); logger . info ( condition , \"Statement only logs if condition is met!\" ) // After that, you can edit myscript.tf and the condition will // re-evaluate the script as needed automatically! // You can delete the file, but doing so will log a warning from `ScriptWatchService` // Recreating a deleted file will trigger an evaluation, same as modification. // Note that the watch service creates a daemon thread to watch the directory. // To free up the thread and stop watching, you should call close() as appropriate: watchService . close (); Please see the scripting example for more details.","title":"Watched Scripts"}]}